{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46692,"status":"ok","timestamp":1701150430507,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"},"user_tz":-480},"id":"oYgpC5sQ5n8V","outputId":"2317aa50-8c78-4286-b4b9-8091ed4bc3b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.2)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow_addons\n","Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n","Collecting rdkit\n","  Downloading rdkit-2023.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n","Installing collected packages: rdkit\n","Successfully installed rdkit-2023.9.2\n","Collecting keras-swa\n","  Downloading keras-swa-0.1.7.tar.gz (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: keras-swa\n","  Building wheel for keras-swa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-swa: filename=keras_swa-0.1.7-py3-none-any.whl size=7823 sha256=cea469816ccee168a42557c83bff6c6c41e4cf8464f21b55786d8ebbe5c61a38\n","  Stored in directory: /root/.cache/pip/wheels/1f/f3/68/48c5eb0509cd523f1c975e1240ae3d97540f6e2666bcdedae4\n","Successfully built keras-swa\n","Installing collected packages: keras-swa\n","Successfully installed keras-swa-0.1.7\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import os\n","import sys\n","import hashlib\n","\n","!pip install tensorflow_addons\n","!pip install rdkit\n","!pip install keras-swa\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow import keras\n","import keras.backend as K\n","from tensorflow.keras import layers\n","from swa.tfkeras import SWA\n","\n","from custom_loss import rwrmse, pseudo_huber, alpha_1point75, alpha_1point5, alpha_1point25, alpha_1point125, alpha_point5, alpha_adaptive, cauchy\n","from custom_loss import rw_cosine_dissimilarity\n","\n","import math as m\n","import numpy as np\n","import pandas as pd\n","import itertools\n","import warnings\n","\n","from rdkit import Chem\n","from rdkit import RDLogger\n","from rdkit.Chem import AllChem\n","from rdkit.Chem import RDKFingerprint\n","\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4EW5zUcI6ICc"},"outputs":[],"source":["# Set random seeds\n","np.random.seed(8)\n","tf.random.set_seed(8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dRBfTR8t6Ph7"},"outputs":[],"source":["# Load training data\n","remove_drugs = True\n","\n","if remove_drugs:\n","  train_path = '/content/drive/MyDrive/Colab Notebooks/Input/singlecell/de_train_small.parquet'\n","  df_train = pd.read_parquet(train_path)\n","else:\n","  train_path = '/content/drive/MyDrive/Colab Notebooks/Input/singlecell/de_train.parquet'\n","  df_train = pd.read_parquet(train_path)"]},{"cell_type":"code","source":["# Get dose values\n","\n","if remove_drugs:\n","  df_logfc = pd.read_parquet('/content/drive/MyDrive/Colab Notebooks/Input/singlecell/logFC_small.parquet')\n","  dose = np.array(df_logfc[\"dose_uM\"])\n","  dose = dose.reshape((df_train.shape[0], 1))\n","else:\n","  df_logfc = pd.read_parquet('/content/drive/MyDrive/Colab Notebooks/Input/singlecell/logFC.parquet')\n","  dose = np.array(df_logfc[\"dose_uM\"])\n","  dose = dose.reshape((df_train.shape[0], 1))"],"metadata":{"id":"YoS82z8_FJC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4IrbFIP96ns0"},"outputs":[],"source":["# Get Morgan fingerprints\n","df_X = np.zeros([df_train.shape[0], 2048])\n","for i in range(df_train.shape[0]):\n","\tdf_X[i, :] = np.array(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(df_train[\"SMILES\"][i]), radius=2, nBits=2048))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkCNYLPy77XL"},"outputs":[],"source":["# One hot encode the cells\n","# One hot ordering: [B cells,  Myeloid cells,  NK cells,  T cells CD4+,  T cells CD8+,  T regulatory cells]\n","one_hot = np.array(pd.get_dummies(df_train[\"cell_type\"]) * 1.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4O3I63_f3x7"},"outputs":[],"source":["# One hot encode controls\n","# 1 - control, 0 - otherwise\n","train_control = np.zeros([df_train.shape[0], 1])\n","for i, cont in enumerate(df_train[\"control\"]):\n","  if cont == True:\n","    train_control[i] = 1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDAu0qC38J_A"},"outputs":[],"source":["# Get log p values for train set\n","\n","if remove_drugs:\n","  df_chem = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Input/singlecell/chemical_properties_small.csv')\n","  # Apply Log10 transform to n_atoms, molecular weight, and molar refractivity\n","  df_chem[\"n_atoms\"] = df_chem[\"n_atoms\"].map(np.log10)\n","  df_chem[\"mol_weight\"] = df_chem[\"mol_weight\"].map(np.log10)\n","  df_chem[\"MR\"] = df_chem[\"MR\"].map(np.log10)\n","else:\n","  df_chem = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Input/singlecell/chemical_properties.csv')\n","  # Apply Log10 transform to n_atoms, molecular weight, and molar refractivity\n","  df_chem[\"n_atoms\"] = df_chem[\"n_atoms\"].map(np.log10)\n","  df_chem[\"mol_weight\"] = df_chem[\"mol_weight\"].map(np.log10)\n","  df_chem[\"MR\"] = df_chem[\"MR\"].map(np.log10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vt4PI77D8LxS","colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"status":"ok","timestamp":1701150442576,"user_tz":-480,"elapsed":5,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"688206fd-f342-440d-ce66-f4e47536846b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["StandardScaler()"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":9}],"source":["# Scale data\n","scaler = StandardScaler()\n","scaler.fit(df_chem[[\"log_P\", \"MR\"]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kp8mjZRW8PGr"},"outputs":[],"source":["# Join to form training matrix\n","# Toggle to include dose and control\n","incl_control = False\n","if incl_control:\n","  one_hot = np.concatenate((one_hot, scaler.transform(df_chem[[\"log_P\", \"MR\"]])), axis=1)\n","  one_hot = np.concatenate((one_hot, train_control), axis=1)\n","  x_train = np.concatenate((one_hot, df_X), axis=1)\n","else:\n","  # Normal features to be used\n","  one_hot = np.concatenate((one_hot, scaler.transform(df_chem[[\"log_P\", \"MR\"]])), axis=1)\n","  x_train = np.concatenate((one_hot, df_X), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9zKi766o5vc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150442576,"user_tz":-480,"elapsed":3,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"20bb2db6-ca41-4afe-a1a7-331d6d423ce1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(548, 2056)"]},"metadata":{},"execution_count":11}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5vye4Li8RL_"},"outputs":[],"source":["# Make train data and targets\n","n_genes = 18211\n","y_train = np.array(df_train.iloc[:, 5:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pmi22Yim3uzU"},"outputs":[],"source":["# Get log FC\n","y_logfc = np.array(df_logfc.iloc[:, 7:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYaxVihDUZsG"},"outputs":[],"source":["# Remove control samples. Takes out rows with cell type and compound exposure used as control\n","# Removing control also reduced the outliers\n","remove_control = False\n","if remove_control:\n","\tcontrol_false = list(df_train.index[df_train[\"control\"] == False])\n","\t# x_train and y_train\n","\tx_train = x_train[control_false, :]\n","\ty_train = y_train[control_false, :]\n","\t# df_train\n","\tdf_train = df_train[df_train[\"control\"] == False]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4B9vd84Vyeh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150467423,"user_tz":-480,"elapsed":2,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"6554e352-5bbc-476c-82df-dd441300d72c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["-127.25861351788677"]},"metadata":{},"execution_count":15}],"source":["np.min(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DuNPYjwS6iy-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150467794,"user_tz":-480,"elapsed":2,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"3b07a8f1-9eeb-435f-ac72-f0bdadab8e0c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["159.27488278365632"]},"metadata":{},"execution_count":16}],"source":["np.max(y_train)"]},{"cell_type":"code","source":["x_train.shape, y_train.shape, y_logfc.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ip5IXy5z9Nwq","executionInfo":{"status":"ok","timestamp":1701150467794,"user_tz":-480,"elapsed":2,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"64212286-98d3-40ce-9795-022b39993aad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((548, 2056), (548, 18211), (548, 18211))"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-5Klv61K2rew"},"outputs":[],"source":["# Gavish Donohoe SVD dimension reduction, returns q, U, S, VT\n","def gd_svd(data_mat, cutoff=\"w_B_high\"):\n","  U, S, VT = np.linalg.svd(data_mat, full_matrices=False)\n","  # Calculate aspect ratio and cutoff\n","  Beta = data_mat.shape[0] / data_mat.shape[1]\n","  # Approximate w(B)\n","  w_B = 0.56 * Beta ** 3 - 0.95 * Beta ** 2 + 1.82 * Beta + 1.43\n","  med_S = np.median(S)\n","  if cutoff == \"w_B\":\n","    tau = w_B * med_S\n","  elif cutoff == \"w_B_low\":\n","    w_B_low = w_B - 0.02\n","    tau = w_B_low * med_S\n","  elif cutoff == \"w_B_high\":\n","    w_B_high = w_B + 0.02\n","    tau = w_B_high * med_S\n","  # Get optimal modes\n","  q = np.max(np.where(S > tau))\n","  U, S, VT = U[:, :(q+1)], np.diag(S[:(q+1)]), VT[:(q+1), :]\n","  return q, U, S, VT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87IPbtvn8U_m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150474989,"user_tz":-480,"elapsed":4535,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"fd3b10ca-2488-4153-cf62-a197aa563b16"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":19}],"source":["# Perform dimension reduction on y_train\n","run_svd = True\n","run_autoencoder = False\n","\n","if run_svd:\n","  q, U, S, VT = gd_svd(data_mat=y_train, cutoff=\"w_B_high\")\n","\n","if run_autoencoder:\n","  encoding_dim = 115\n","  # Load in AE model\n","  ae_target = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/AE Models/sign_logpv_autoencoder_linear_embed_600e_115.h5')\n","  # Encoder\n","  encoder = keras.Model(inputs=ae_target.input, outputs=ae_target.layers[7].output)\n","  # Decoder\n","  decoder = keras.Model(inputs=ae_target.layers[8].input, outputs=ae_target.layers[-1].output)\n","\n","q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MGp7aOuD8aBM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150474990,"user_tz":-480,"elapsed":4,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"afc8b956-7acd-4a99-b839-b07a9aa5a5e3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(548, 101)"]},"metadata":{},"execution_count":20}],"source":["# Get embeddings for y_train\n","if run_svd:\n","  # Calculate denoised y_train\n","  y_train_tilde = U @ S @ VT\n","  # Get y_embed\n","  y_embed = U @ S\n","\n","if run_autoencoder:\n","  # Get y_embed\n","  y_embed = encoder.predict(y_train)\n","\n","y_embed.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DkwxCHK03sNC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150480548,"user_tz":-480,"elapsed":5560,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"776d605f-33c1-4001-d373-893d0624a751"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["61"]},"metadata":{},"execution_count":21}],"source":["# Perform SVD on logfc\n","if run_svd:\n","  k, U_lfc, S_lfc, VT_lfc = gd_svd(data_mat=y_logfc, cutoff=\"w_B_high\")\n","\n","k"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8r9L36cD32Dc"},"outputs":[],"source":["# Get embeddings for log FC\n","if run_svd:\n","  # Calculate embeddings as features\n","  y_embed_logfc = U_lfc @ S_lfc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4rIl22tY34RX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150480548,"user_tz":-480,"elapsed":4,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"8e32d199-71fd-463a-d3cb-5bcc72c6d6e3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(518.4002568778097,\n"," -1572.9470212129154,\n"," 228.0118583629156,\n"," -418.21068628665535)"]},"metadata":{},"execution_count":23}],"source":["np.max(y_embed), np.min(y_embed), np.max(y_embed_logfc), np.min(y_embed_logfc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnVlzRK837zg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150480548,"user_tz":-480,"elapsed":3,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"341b9766-6991-4f6c-8bfd-9c0dc9833e86"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((548, 2056), (548, 101), (548, 62))"]},"metadata":{},"execution_count":24}],"source":["x_train.shape, y_embed.shape, y_embed_logfc.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqG7oxRb2Seh"},"outputs":[],"source":["# Augment features with average drug response and average cell type response to drugs\n","# P-val responses\n","# Embedding features\n","embedding_features = False\n","\n","# Drug response, cell type response\n","drug_response = False\n","cell_type_response = False\n","# Log FC response\n","drug_lfc_response = False\n","cell_type_lfc_response = False\n","\n","if drug_response:\n","  scaler_drug = StandardScaler()\n","  if embedding_features:\n","    df_smiles_name = df_train.iloc[:, [3]]\n","    df_smiles_name = pd.concat((df_smiles_name, pd.DataFrame(y_embed)), axis=1) # Use SVD embeddings to average over\n","  else:\n","    # Normal dimension features\n","    df_smiles_name = df_train.iloc[:, [3] + list(range(5, df_train.shape[1]))]\n","  mean_smiles_name = df_smiles_name.groupby('SMILES').mean().reset_index()\n","  df_train_alt = df_train.iloc[:, 0:5]\n","  df_train_alt = df_train_alt.merge(mean_smiles_name, on='SMILES', how='left')\n","  mean_smiles_train = np.array(df_train_alt.iloc[:, 5:])\n","  # Fit and transform\n","  scaler_drug.fit(mean_smiles_train)\n","  # Concat with x_train\n","  x_train = np.concatenate((x_train, scaler_drug.transform(mean_smiles_train)), axis=1)\n","\n","if cell_type_response:\n","  scaler_cell = StandardScaler()\n","  if embedding_features:\n","    df_cell_type = df_train.iloc[:, [0]]\n","    df_cell_type = pd.concat((df_cell_type, pd.DataFrame(y_embed)), axis=1)\n","  else:\n","    # Normal dimension features\n","    df_cell_type = df_train.iloc[:, [0] + list(range(5, df_train.shape[1]))]\n","  mean_cell_type = df_cell_type.groupby('cell_type').mean().reset_index()\n","  df_train_alt = df_train.iloc[:, 0:5]\n","  df_train_alt = df_train_alt.merge(mean_cell_type, on='cell_type', how='left')\n","  mean_cell_train = np.array(df_train_alt.iloc[:, 5:])\n","  # Fit and transform\n","  scaler_cell.fit(mean_cell_train)\n","  # Concat with x_train\n","  x_train = np.concatenate((x_train, scaler_cell.transform(mean_cell_train)), axis=1)\n","\n","if drug_lfc_response:\n","  scaler_drug_lfc = StandardScaler()\n","  if embedding_features:\n","    df_smiles_name = df_train.iloc[:, [3]]\n","    df_smiles_name = pd.concat((df_smiles_name, pd.DataFrame(y_embed_logfc)), axis=1)\n","  else:\n","    # Normal dimension features\n","    df_smiles_name = df_train.iloc[:, [3]]\n","    df_smiles_name = pd.concat((df_smiles_name, df_logfc.iloc[:, 7:]), axis=1)\n","  mean_smiles_lfc_name = df_smiles_name.groupby('SMILES').mean().reset_index()\n","  df_train_alt = df_train.iloc[:, 0:5]\n","  df_train_alt = df_train_alt.merge(mean_smiles_lfc_name, on='SMILES', how='left')\n","  mean_smiles_lfc_train = np.array(df_train_alt.iloc[:, 5:])\n","  # Fit and transform\n","  scaler_drug_lfc.fit(mean_smiles_lfc_train)\n","  # Concat with x_train\n","  x_train = np.concatenate((x_train, scaler_drug_lfc.transform(mean_smiles_lfc_train)), axis=1)\n","\n","if cell_type_lfc_response:\n","  scaler_cell_lfc = StandardScaler()\n","  if embedding_features:\n","    df_cell_type = df_train.iloc[:, [0]]\n","    df_cell_type = pd.concat((df_cell_type, pd.DataFrame(y_embed_logfc)), axis=1)\n","  else:\n","    # Normal dimension features\n","    df_cell_type = df_train.iloc[:, [0]]\n","    df_cell_type = pd.concat((df_cell_type, df_logfc.iloc[:, 7:]), axis=1)\n","  mean_cell_lfc_type = df_cell_type.groupby('cell_type').mean().reset_index()\n","  df_train_alt = df_train.iloc[:, 0:5]\n","  df_train_alt = df_train_alt.merge(mean_cell_lfc_type, on='cell_type', how='left')\n","  mean_cell_lfc_train = np.array(df_train_alt.iloc[:, 5:])\n","  # Fit and transform\n","  scaler_cell_lfc.fit(mean_cell_lfc_train)\n","  # Concat with x_train\n","  x_train = np.concatenate((x_train, scaler_cell_lfc.transform(mean_cell_lfc_train)), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O9Q3yIA-4vZg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150484271,"user_tz":-480,"elapsed":2,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"56198749-2ff0-456a-a493-4ac695755ae0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(548, 2056)"]},"metadata":{},"execution_count":26}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsF4-2Ssj_N6"},"outputs":[],"source":["# Keep copy of x_train in original row order wrt df_train\n","x_train_copy = x_train\n","y_train_copy = y_train\n","y_embed_copy = y_embed"]},{"cell_type":"code","source":["x_train.shape, y_train.shape, y_embed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNuLXH4nhpgd","executionInfo":{"status":"ok","timestamp":1701150486920,"user_tz":-480,"elapsed":1,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"7ebbbb34-5ca2-4b80-b62d-2d4123f0344d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((548, 2056), (548, 18211), (548, 101))"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXGEZpYnkD1j"},"outputs":[],"source":["# Sign regression index list 75% accuracy (from sign regression JTT)\n","idx_list = [  8,   9,  10,  11,  12,  30,  31,  32,  33,  34,  38,  40,  56,\n","        72,  73,  74,  75,  76,  86,  87,  90,  91,  94,  95,  96,  97,\n","       118, 130, 151, 154, 155, 156, 157, 158, 168, 169, 170, 171, 174,\n","       193, 194, 201, 202, 223, 229, 230, 233, 234, 235, 236, 267, 268,\n","       271, 272, 297, 309, 313, 315, 316, 317, 327, 336, 377, 381, 382,\n","       405, 409, 410, 411, 412, 413, 414, 419, 447, 448, 451, 452, 456,\n","       459, 460, 467, 475, 477, 478, 517, 518, 519, 520, 521, 523, 540,\n","       541, 556, 557, 558, 559, 579, 602, 603, 607]"]},{"cell_type":"code","source":["# Sign regression index list -2 STD accuracy (from sign regression JTT after drugs not in test removed)\n","# Index is from 0 to 545, not 0 to 614. This sign based filtering was done on training set with drugs removed\n","idx_list = [  0,  10,  11,  20,  23,  28,  29,  30,  32,  33,  44,  48,  52,\n","        53,  55,  64,  65,  70,  74,  75,  78,  79,  82,  98,  99, 110,\n","       127, 131, 132, 143, 144, 154, 158, 162, 163, 167, 170, 171, 178,\n","       182, 183, 186, 190, 191, 192, 199, 202, 203, 212, 232, 233, 236,\n","       237, 254, 255, 258, 259, 262, 263, 270, 273, 276, 278, 280, 281,\n","       292, 293, 295, 296, 312, 320, 323, 330, 331, 334, 335, 347, 358,\n","       359, 362, 364, 368, 369, 372, 376, 388, 396, 398, 399, 400, 405,\n","       408, 409, 412, 413, 416, 417, 420, 421, 423, 426, 442, 443, 446,\n","       458, 463, 465, 478, 479, 486, 494, 495, 496, 497, 500, 501, 508,\n","       509, 512, 513, 514, 515, 524, 536, 537, 539, 540, 541, 544, 545]"],"metadata":{"id":"ulgyR2_NhBOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9I9zGJ7bkFZT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150490117,"user_tz":-480,"elapsed":2,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"40094ab1-a905-4259-9cd8-fbd8a98f196c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["130"]},"metadata":{},"execution_count":30}],"source":["len(idx_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgcR9GuzkIDA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150490781,"user_tz":-480,"elapsed":2,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"65023e9e-6383-4ec9-e383-8fe5a0e38e1a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((130, 2056), (130, 101), (130, 18211))"]},"metadata":{},"execution_count":31}],"source":["# Get samples which had large error in train to upsample from\n","x_train_upsample = x_train[idx_list, :]\n","y_train_upsample = y_train[idx_list, :]\n","y_embed_upsample = y_embed[idx_list, :]\n","\n","x_train_upsample.shape, y_embed_upsample.shape, y_train_upsample.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XmtJrbeCkKJ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150491662,"user_tz":-480,"elapsed":2,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"083fb950-bdab-4c03-d2d3-3ef88e419ea4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((780, 2056), (780, 101), (780, 18211))"]},"metadata":{},"execution_count":32}],"source":["# Generate new samples\n","scaling_factor = 6\n","new_samples_x = x_train_upsample\n","new_samples_y_train = y_train_upsample\n","new_samples_y_embed = y_embed_upsample\n","\n","for i in range(1, scaling_factor, 1):\n","  new_samples_x = np.concatenate((new_samples_x, x_train_upsample), axis=0)\n","  new_samples_y_train = np.concatenate((new_samples_y_train, y_train_upsample), axis=0)\n","  new_samples_y_embed = np.concatenate((new_samples_y_embed, y_embed_upsample), axis=0)\n","\n","new_samples_x.shape, new_samples_y_embed.shape, new_samples_y_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Femu8zJQkRLQ"},"outputs":[],"source":["# Concatenate results to original x_train and y_embed\n","x_train = np.concatenate((x_train, new_samples_x), axis=0)\n","y_train = np.concatenate((y_train, new_samples_y_train), axis=0)\n","y_embed = np.concatenate((y_embed, new_samples_y_embed), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0hrc8DgkSw6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150494245,"user_tz":-480,"elapsed":2,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"4348accd-53b0-4abf-a33b-09138d90f8f7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1328, 2056), (1328, 101), (1328, 18211))"]},"metadata":{},"execution_count":34}],"source":["x_train.shape, y_embed.shape, y_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AWB-3tA8fPD"},"outputs":[],"source":["# Shuffle data\n","permuted_indices = np.random.permutation(np.arange(x_train.shape[0]))\n","x_train = x_train[permuted_indices, :]\n","y_train = y_train[permuted_indices, :]\n","y_embed = y_embed[permuted_indices, :]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vsqvdcg1svHy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701150497374,"user_tz":-480,"elapsed":1,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"838aef27-d54a-4307-b9ca-04697559274d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1328, 2056), (1328, 18211), (1328, 101))"]},"metadata":{},"execution_count":37}],"source":["x_train.shape, y_train.shape, y_embed.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pUvRG3iKjCdz"},"outputs":[],"source":["# Model\n","# Architecture selection - 3 heads for contrastive loss, 3 choose 2 = 3 combinations\n","# Can also try 2 head contrastive model\n","def create_3_head(VT_project=False):\n","  # One input, 3 outputs\n","  input_size = x_train.shape[1]\n","  inputs_reg = layers.Input((input_size,))\n","  x_1 = layers.Dense(5128, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(inputs_reg)\n","  x_2 = layers.Dense(5128, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(x_1)\n","  x_3 = layers.Dense(5128, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(x_2)\n","  x_4 = layers.Dense(5128, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(x_3)\n","  x_5 = layers.Dense(5128, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(x_4)\n","  # Head 1\n","  h_1_1 = layers.Dense(3072, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(x_5)\n","  h_1_2 = layers.Dense(2048, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(h_1_1)\n","  h_1_3 = layers.Dense(1024, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(h_1_2)\n","  if run_svd:\n","    if VT_project:\n","      output_embed_1 = layers.Dense((q+1), kernel_initializer=\"glorot_normal\")(h_1_3)\n","      output_h_1 = layers.Dense(n_genes, use_bias=False, trainable=False, name=\"output_h_1\")(output_embed_1)\n","    else:\n","      output_h_1 = layers.Dense((q+1), kernel_initializer=\"glorot_normal\")(h_1_3)\n","  if run_autoencoder:\n","    output_h_1 = layers.Dense(encoding_dim, kernel_initializer=\"glorot_normal\")(h_1_3)\n","  # Head 2, vary architecture slightly\n","  h_2_1 = layers.Dense(3072, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(x_5)\n","  h_2_2 = layers.Dense(2048, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(h_2_1)\n","  h_2_3 = layers.Dense(1024, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(h_2_2)\n","  if run_svd:\n","    if VT_project:\n","      output_embed_2 = layers.Dense((q+1), kernel_initializer=\"glorot_normal\")(h_2_3)\n","      output_h_2 = layers.Dense(n_genes, use_bias=False, trainable=False, name=\"output_h_2\")(output_embed_2)\n","    else:\n","      output_h_2 = layers.Dense((q+1), kernel_initializer=\"glorot_normal\")(h_2_3)\n","  if run_autoencoder:\n","    output_h_2 = layers.Dense(encoding_dim, kernel_initializer=\"glorot_normal\")(h_2_3)\n","  # Head 3, vary architecture slightly\n","  h_3_1 = layers.Dense(3072, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(x_5)\n","  h_3_2 = layers.Dense(2048, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(h_3_1)\n","  h_3_3 = layers.Dense(1024, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\")(h_3_2)\n","  if run_svd:\n","    if VT_project:\n","      output_embed_3 = layers.Dense((q+1), kernel_initializer=\"glorot_normal\")(h_3_3)\n","      output_h_3 = layers.Dense(n_genes, use_bias=False, trainable=False, name=\"output_h_3\")(output_embed_3)\n","    else:\n","      output_h_3 = layers.Dense((q+1), kernel_initializer=\"glorot_normal\")(h_3_3)\n","  if run_autoencoder:\n","    output_h_3 = layers.Dense(encoding_dim, kernel_initializer=\"glorot_normal\")(h_3_3)\n","  # Concat layer\n","  concat = layers.Concatenate(axis=-1)([output_h_1, output_h_2, output_h_3])\n","  model = keras.Model(inputs=inputs_reg, outputs=concat)\n","  return model\n","\n","def create_n_head(n_heads, VT_project=False):\n","  input_size = x_train.shape[1]\n","  inputs_reg = layers.Input((input_size,))\n","  # Shared model weights\n","  x_1 = layers.Dense(5128, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\", name=\"shared_1\")(inputs_reg)\n","  x_2 = layers.Dense(5128, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\", name=\"shared_2\")(x_1)\n","  x_3 = layers.Dense(5128, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\", name=\"shared_3\")(x_2)\n","  x_4 = layers.Dense(5128, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\", name=\"shared_4\")(x_3)\n","  x_5 = layers.Dense(5128, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\", name=\"shared_5\")(x_4)\n","  # Create n_heads - specialise based on loss function used\n","  concat_list = []\n","  for i in range(1, n_heads+1, 1):\n","    globals()['h_' + str(i) + '_1'] = layers.Dense(3072, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\", name=\"head_\" + str(i) + \"_l_1\")(x_5)\n","    globals()['h_' + str(i) + '_2'] = layers.Dense(2048, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\", name=\"head_\" + str(i) + \"_l_2\")(globals()['h_' + str(i) + '_1'])\n","    globals()['h_' + str(i) + '_3'] = layers.Dense(1024, activation=\"selu\", kernel_initializer=\"lecun_normal\", bias_initializer=\"zeros\", name=\"head_\" + str(i) + \"_l_3\")(globals()['h_' + str(i) + '_2'])\n","    if run_svd:\n","      if VT_project:\n","        globals()['output_' + 'embed_' + str(i)] = layers.Dense((q+1), kernel_initializer=\"glorot_normal\", name=\"embed_\" + str(i))(globals()['h_' + str(i) + '_3'])\n","        globals()['output_' + 'h_' + str(i)] = layers.Dense(n_genes, use_bias=False, trainable=False, name=\"head_\" + str(i) + \"_out\")(globals()['output_' + 'embed_' + str(i)])\n","      else:\n","        globals()['output_' + 'h_' + str(i)] = layers.Dense((q+1), kernel_initializer=\"glorot_normal\", name=\"head_\" + str(i) + \"_out\")(globals()['h_' + str(i) + '_3'])\n","    if run_autoencoder:\n","      globals()['output_' + 'h_' + str(i)] = layers.Dense(encoding_dim, kernel_initializer=\"glorot_normal\", name=\"head_\" + str(i) + \"_out\")(globals()['h_' + str(i) + '_3'])\n","    # Add output layer to concat list to feed into concat layer\n","    concat_list.append(globals()['output_' + 'h_' + str(i)])\n","  # Concat layer\n","  concat = layers.Concatenate(axis=-1, name=\"concat_layer\")(concat_list)\n","  model = keras.Model(inputs=inputs_reg, outputs=concat)\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Abr6zzd8q1Eq"},"outputs":[],"source":["# Create model\n","# Select VT projection, if False regression heads are modelled on y_embed\n","VT_project = False\n","\n","model = create_3_head(VT_project=VT_project)\n","\n","# 2/3 head model\n","#model = create_n_head(n_heads=3, VT_project=VT_project)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPLtCFnQp9z3"},"outputs":[],"source":["# VT project\n","# Set last weight matrix as VT projection matrix from SVD\n","if VT_project:\n","  w_VT = [VT]\n","  # Set VT matrix as weights for layers -2, -3, -4\n","  model.layers[-2].set_weights(w_VT)\n","  model.layers[-3].set_weights(w_VT)\n","  model.layers[-4].set_weights(w_VT)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fk13KpgwaExU","outputId":"3d178c1c-b827-4d55-9391-48dea8afc8bb","executionInfo":{"status":"ok","timestamp":1701150505430,"user_tz":-480,"elapsed":825,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 2056)]               0         []                            \n","                                                                                                  \n"," dense (Dense)               (None, 5128)                 1054829   ['input_1[0][0]']             \n","                                                          6                                       \n","                                                                                                  \n"," dense_1 (Dense)             (None, 5128)                 2630151   ['dense[0][0]']               \n","                                                          2                                       \n","                                                                                                  \n"," dense_2 (Dense)             (None, 5128)                 2630151   ['dense_1[0][0]']             \n","                                                          2                                       \n","                                                                                                  \n"," dense_3 (Dense)             (None, 5128)                 2630151   ['dense_2[0][0]']             \n","                                                          2                                       \n","                                                                                                  \n"," dense_4 (Dense)             (None, 5128)                 2630151   ['dense_3[0][0]']             \n","                                                          2                                       \n","                                                                                                  \n"," dense_5 (Dense)             (None, 3072)                 1575628   ['dense_4[0][0]']             \n","                                                          8                                       \n","                                                                                                  \n"," dense_9 (Dense)             (None, 3072)                 1575628   ['dense_4[0][0]']             \n","                                                          8                                       \n","                                                                                                  \n"," dense_13 (Dense)            (None, 3072)                 1575628   ['dense_4[0][0]']             \n","                                                          8                                       \n","                                                                                                  \n"," dense_6 (Dense)             (None, 2048)                 6293504   ['dense_5[0][0]']             \n","                                                                                                  \n"," dense_10 (Dense)            (None, 2048)                 6293504   ['dense_9[0][0]']             \n","                                                                                                  \n"," dense_14 (Dense)            (None, 2048)                 6293504   ['dense_13[0][0]']            \n","                                                                                                  \n"," dense_7 (Dense)             (None, 1024)                 2098176   ['dense_6[0][0]']             \n","                                                                                                  \n"," dense_11 (Dense)            (None, 1024)                 2098176   ['dense_10[0][0]']            \n","                                                                                                  \n"," dense_15 (Dense)            (None, 1024)                 2098176   ['dense_14[0][0]']            \n","                                                                                                  \n"," dense_8 (Dense)             (None, 101)                  103525    ['dense_7[0][0]']             \n","                                                                                                  \n"," dense_12 (Dense)            (None, 101)                  103525    ['dense_11[0][0]']            \n","                                                                                                  \n"," dense_16 (Dense)            (None, 101)                  103525    ['dense_15[0][0]']            \n","                                                                                                  \n"," concatenate (Concatenate)   (None, 303)                  0         ['dense_8[0][0]',             \n","                                                                     'dense_12[0][0]',            \n","                                                                     'dense_16[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 188508823 (719.10 MB)\n","Trainable params: 188508823 (719.10 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUB4FyjCjFr7"},"outputs":[],"source":["# Define losses\n","def contrastive_loss_3h(y_true, y_pred):\n","  # n heads\n","  n = 3\n","  # Weights\n","  w_contrast = 0.5\n","  # MAE used for regression losses for each head\n","  loss_fn_1 = keras.losses.MeanAbsoluteError()\n","  loss_fn_2 = keras.losses.MeanAbsoluteError()\n","  loss_fn_3 = keras.losses.MeanAbsoluteError()\n","  # Split concat into chunks\n","  chunks = tf.split(y_pred, num_or_size_splits=n, axis=1)\n","  # Calculate pairwise loss for each pair\n","  c_l = 0.\n","  for pair in itertools.combinations(chunks, 2):\n","    c_l += rw_cosine_dissimilarity(pair[0], pair[1])\n","  # Calculate head regression losses\n","  loss_list = [loss_fn_1, loss_fn_2, loss_fn_3]\n","  h_l = 0.\n","  for i in range(n):\n","    h_l += loss_list[i](y_true, chunks[i])\n","  # MAE plus weighted average pairwise cosine dis-similarity\n","  return h_l + w_contrast * (c_l / 3.)\n","\n","# Contrastive loss multi losses\n","def contrastive_loss_multi_3h(y_true, y_pred):\n","  # n heads\n","  n = 3\n","  # Weights - may need to reduce w_contrast as some losses are smaller in value numerically\n","  w_contrast = 0.5 # 0.5 value corresponds to a 36% decrease in contrast loss commensurate with smaller loss sum from use of logcosh and huber\n","  # Define regression losses for each head\n","  # MAE, logcosh, huber losses\n","  mae = keras.losses.MeanAbsoluteError()\n","  logcosh = keras.losses.LogCosh()\n","  huber = keras.losses.Huber()\n","  # Split concat into cunks\n","  chunks = tf.split(y_pred, num_or_size_splits=3, axis=1)\n","  # Calculate pairwise loss for each pair\n","  c_l = 0.\n","  for pair in itertools.combinations(chunks, 2):\n","    c_l += rw_cosine_dissimilarity(pair[0], pair[1])\n","  # Calculate head regression losses\n","  loss_list = [mae, logcosh, huber]\n","  h_l = 0.\n","  for i in range(n):\n","    h_l += loss_list[i](y_true, chunks[i])\n","  # Return total losses\n","  return h_l + w_contrast * (c_l / 3)\n","\n","# Multi-head additive loss (can add contratistive)\n","# Can try cosine similarity\n","def multi_loss(y_true, y_pred):\n","  # n heads\n","  n = 8\n","  # Split into chunks e.g.\n","  chunks = tf.split(y_pred, num_or_size_splits=8, axis=1)\n","  # Define losses\n","  mae = keras.losses.MeanAbsoluteError()\n","  logcosh = keras.losses.LogCosh()\n","  huber = keras.losses.Huber() # rwrmse, pseudo_huber, alpha_1point75, alpha_1point5, alpha_1point25, alpha_point5, cauchy, geman_mcclure\n","  # cosine = keras.losses.CosineSimilarity()\n","  # Define loss list for each head\n","  loss_list = [mae, logcosh, huber, pseudo_huber, alpha_1point75, alpha_1point5, alpha_1point25, alpha_1point125]\n","  h_l = 0.\n","  for i in range(n):\n","    h_l += loss_list[i](y_true, chunks[i])\n","  # Return total losses\n","  return h_l\n","\n","# Multi-head additive loss with contrast\n","def multi_loss_contrastive(y_true, y_pred):\n","  # n heads\n","  n = 8\n","  # Weights\n","  w_contrast = 0.8\n","  # Split into chunks e.g.\n","  chunks = tf.split(y_pred, num_or_size_splits=8, axis=1)\n","  # Define losses\n","  mae = keras.losses.MeanAbsoluteError()\n","  logcosh = keras.losses.LogCosh()\n","  huber = keras.losses.Huber() # rwrmse, pseudo_huber, alpha_1point75, alpha_1point5, alpha_1point25, alpha_point5, cauchy, geman_mcclure\n","  # cosine = keras.losses.CosineSimilarity()\n","  # Calculate pairwise dis-similarity\n","  c_l = 0.\n","  for pair in itertools.combinations(chunks, 2):\n","    c_l += rw_cosine_dissimilarity(pair[0], pair[1])\n","  # Define loss list for each head\n","  loss_list = [mae, logcosh, huber, pseudo_huber, alpha_1point75, alpha_1point5, alpha_1point25, alpha_1point125]\n","  h_l = 0.\n","  for i in range(n):\n","    h_l += loss_list[i](y_true, chunks[i])\n","  # Return total losses\n","  return h_l + w_contrast * (c_l / 28)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AwCoL-k8KPef"},"outputs":[],"source":["# Average chunk rwrmse loss\n","# Change n to 3 if using contrastive loss, else change to number of heads for ensemble\n","def multi_rwrmse(y_true, y_pred):\n","\t# n heads\n","\tn = 3\n","\t# Combine y_true\n","\ty_true_list = []\n","\tfor i in range(n):\n","\t\ty_true_list.append(y_true)\n","\ty_true_comb = tf.concat(y_true_list, axis=1)\n","\treturn rwrmse(y_true_comb, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrOIU22YjKHh"},"outputs":[],"source":["# Stochastic weight averaging\n","# Try SWA averaging starting at epoch 1,000\n","start_epoch = 2\n","swa = SWA(start_epoch=start_epoch,\n","          lr_schedule='manual',\n","          verbose=1)\n","\n","# Optimizer\n","# Best scores used learning rate 7e-5, and SWA learning rate 5e-5\n","learning_rate = 7e-5 # 7e-5 for AdamW, 1e-5 / 7e-6 using Lion\n","\n","# Cosine rate scheduler\n","cos_sched = keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate=learning_rate, first_decay_steps=16600, t_mul=1.0, m_mul=0.9, alpha=0.01)\n","\n","# Optimisers\n","# Try higher weight decay for larger models\n","# lambda = lambda(norm) * sqrt(batch_size / (n * t)), where n is number of training points and t is number of epochs\n","# Try lambda(norm) between 0.025 to 0.05\n","weight_decay = 0.1\n","opt = keras.optimizers.legacy.Adam(learning_rate=cos_sched)\n","\n","opt_adamW = keras.optimizers.AdamW(learning_rate=cos_sched)\n","\n","opt_lion = keras.optimizers.Lion(learning_rate=cos_sched, weight_decay=weight_decay)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KpT7rkrDjNBd","outputId":"236a445e-4e7a-465e-9917-9de993e2bb28","executionInfo":{"status":"ok","timestamp":1701153034253,"user_tz":-480,"elapsed":2492728,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/800\n"," 5/83 [>.............................] - ETA: 2s - loss: 14.9031 - multi_rwrmse: 8.8050"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0118s vs `on_train_batch_end` time: 0.0125s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["83/83 [==============================] - 21s 28ms/step - loss: 13.0214 - multi_rwrmse: 7.7852\n","\n","Epoch 00002: starting stochastic weight averaging\n","Epoch 2/800\n","83/83 [==============================] - 4s 54ms/step - loss: 10.6378 - multi_rwrmse: 6.7766\n","Epoch 3/800\n","83/83 [==============================] - 3s 40ms/step - loss: 9.4438 - multi_rwrmse: 6.0894\n","Epoch 4/800\n","83/83 [==============================] - 3s 40ms/step - loss: 8.6250 - multi_rwrmse: 5.6540\n","Epoch 5/800\n","83/83 [==============================] - 3s 40ms/step - loss: 8.1695 - multi_rwrmse: 5.3780\n","Epoch 6/800\n","83/83 [==============================] - 4s 43ms/step - loss: 7.8064 - multi_rwrmse: 5.1525\n","Epoch 7/800\n","83/83 [==============================] - 5s 55ms/step - loss: 7.3809 - multi_rwrmse: 4.8915\n","Epoch 8/800\n","83/83 [==============================] - 3s 38ms/step - loss: 6.9958 - multi_rwrmse: 4.6258\n","Epoch 9/800\n","83/83 [==============================] - 3s 39ms/step - loss: 6.8120 - multi_rwrmse: 4.4703\n","Epoch 10/800\n","83/83 [==============================] - 3s 37ms/step - loss: 6.6835 - multi_rwrmse: 4.3383\n","Epoch 11/800\n","83/83 [==============================] - 3s 40ms/step - loss: 6.5536 - multi_rwrmse: 4.2184\n","Epoch 12/800\n","83/83 [==============================] - 3s 39ms/step - loss: 6.2942 - multi_rwrmse: 4.0504\n","Epoch 13/800\n","83/83 [==============================] - 3s 37ms/step - loss: 6.2095 - multi_rwrmse: 3.9633\n","Epoch 14/800\n","83/83 [==============================] - 3s 36ms/step - loss: 5.9774 - multi_rwrmse: 3.7639\n","Epoch 15/800\n","83/83 [==============================] - 3s 36ms/step - loss: 5.8647 - multi_rwrmse: 3.7103\n","Epoch 16/800\n","83/83 [==============================] - 3s 38ms/step - loss: 5.6987 - multi_rwrmse: 3.5439\n","Epoch 17/800\n","83/83 [==============================] - 3s 39ms/step - loss: 5.7732 - multi_rwrmse: 3.5244\n","Epoch 18/800\n","83/83 [==============================] - 3s 36ms/step - loss: 5.5169 - multi_rwrmse: 3.3111\n","Epoch 19/800\n","83/83 [==============================] - 3s 42ms/step - loss: 5.3735 - multi_rwrmse: 3.2574\n","Epoch 20/800\n","83/83 [==============================] - 3s 38ms/step - loss: 5.2646 - multi_rwrmse: 3.1189\n","Epoch 21/800\n","83/83 [==============================] - 3s 38ms/step - loss: 5.4092 - multi_rwrmse: 3.1372\n","Epoch 22/800\n","83/83 [==============================] - 3s 38ms/step - loss: 5.1830 - multi_rwrmse: 3.0920\n","Epoch 23/800\n","83/83 [==============================] - 3s 37ms/step - loss: 4.9348 - multi_rwrmse: 2.8458\n","Epoch 24/800\n","83/83 [==============================] - 3s 36ms/step - loss: 4.8522 - multi_rwrmse: 2.7827\n","Epoch 25/800\n","83/83 [==============================] - 3s 36ms/step - loss: 4.9333 - multi_rwrmse: 2.7185\n","Epoch 26/800\n","83/83 [==============================] - 3s 36ms/step - loss: 4.9916 - multi_rwrmse: 2.8709\n","Epoch 27/800\n","83/83 [==============================] - 3s 38ms/step - loss: 4.8152 - multi_rwrmse: 2.7784\n","Epoch 28/800\n","83/83 [==============================] - 3s 41ms/step - loss: 4.6249 - multi_rwrmse: 2.6107\n","Epoch 29/800\n","83/83 [==============================] - 3s 35ms/step - loss: 4.4631 - multi_rwrmse: 2.5428\n","Epoch 30/800\n","83/83 [==============================] - 3s 35ms/step - loss: 4.3497 - multi_rwrmse: 2.3370\n","Epoch 31/800\n","83/83 [==============================] - 3s 35ms/step - loss: 4.3286 - multi_rwrmse: 2.3050\n","Epoch 32/800\n","83/83 [==============================] - 3s 38ms/step - loss: 4.2850 - multi_rwrmse: 2.3365\n","Epoch 33/800\n","83/83 [==============================] - 3s 38ms/step - loss: 4.2329 - multi_rwrmse: 2.2481\n","Epoch 34/800\n","83/83 [==============================] - 3s 36ms/step - loss: 4.1733 - multi_rwrmse: 2.1935\n","Epoch 35/800\n","83/83 [==============================] - 3s 37ms/step - loss: 4.1481 - multi_rwrmse: 2.2045\n","Epoch 36/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.9798 - multi_rwrmse: 2.0108\n","Epoch 37/800\n","83/83 [==============================] - 3s 37ms/step - loss: 4.0428 - multi_rwrmse: 2.1789\n","Epoch 38/800\n","83/83 [==============================] - 3s 38ms/step - loss: 3.9922 - multi_rwrmse: 2.1679\n","Epoch 39/800\n","83/83 [==============================] - 3s 38ms/step - loss: 3.9313 - multi_rwrmse: 2.0130\n","Epoch 40/800\n","83/83 [==============================] - 3s 35ms/step - loss: 3.7838 - multi_rwrmse: 1.9537\n","Epoch 41/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.7800 - multi_rwrmse: 1.9866\n","Epoch 42/800\n","83/83 [==============================] - 3s 35ms/step - loss: 3.7499 - multi_rwrmse: 1.9428\n","Epoch 43/800\n","83/83 [==============================] - 3s 37ms/step - loss: 3.7074 - multi_rwrmse: 1.8683\n","Epoch 44/800\n","83/83 [==============================] - 3s 38ms/step - loss: 3.7666 - multi_rwrmse: 1.9443\n","Epoch 45/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.5968 - multi_rwrmse: 1.7719\n","Epoch 46/800\n","83/83 [==============================] - 3s 35ms/step - loss: 3.5266 - multi_rwrmse: 1.7380\n","Epoch 47/800\n","83/83 [==============================] - 3s 37ms/step - loss: 3.4538 - multi_rwrmse: 1.6892\n","Epoch 48/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.3849 - multi_rwrmse: 1.6502\n","Epoch 49/800\n","83/83 [==============================] - 3s 38ms/step - loss: 3.2877 - multi_rwrmse: 1.5711\n","Epoch 50/800\n","83/83 [==============================] - 3s 37ms/step - loss: 3.2540 - multi_rwrmse: 1.5494\n","Epoch 51/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.2492 - multi_rwrmse: 1.5098\n","Epoch 52/800\n","83/83 [==============================] - 3s 37ms/step - loss: 3.2503 - multi_rwrmse: 1.5332\n","Epoch 53/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.2856 - multi_rwrmse: 1.6461\n","Epoch 54/800\n","83/83 [==============================] - 3s 38ms/step - loss: 3.3973 - multi_rwrmse: 1.7194\n","Epoch 55/800\n","83/83 [==============================] - 3s 38ms/step - loss: 3.4070 - multi_rwrmse: 1.6651\n","Epoch 56/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.4326 - multi_rwrmse: 1.6993\n","Epoch 57/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.6184 - multi_rwrmse: 1.8382\n","Epoch 58/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.6723 - multi_rwrmse: 1.9961\n","Epoch 59/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.4198 - multi_rwrmse: 1.7427\n","Epoch 60/800\n","83/83 [==============================] - 3s 38ms/step - loss: 3.1848 - multi_rwrmse: 1.5072\n","Epoch 61/800\n","83/83 [==============================] - 3s 37ms/step - loss: 3.1569 - multi_rwrmse: 1.5287\n","Epoch 62/800\n","83/83 [==============================] - 3s 35ms/step - loss: 3.0742 - multi_rwrmse: 1.4802\n","Epoch 63/800\n","83/83 [==============================] - 3s 35ms/step - loss: 3.1941 - multi_rwrmse: 1.5813\n","Epoch 64/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.9572 - multi_rwrmse: 1.3648\n","Epoch 65/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.8505 - multi_rwrmse: 1.2226\n","Epoch 66/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.7881 - multi_rwrmse: 1.1904\n","Epoch 67/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.8788 - multi_rwrmse: 1.2338\n","Epoch 68/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.8691 - multi_rwrmse: 1.2566\n","Epoch 69/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.8182 - multi_rwrmse: 1.1947\n","Epoch 70/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.7876 - multi_rwrmse: 1.1916\n","Epoch 71/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.7760 - multi_rwrmse: 1.1818\n","Epoch 72/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.7596 - multi_rwrmse: 1.2318\n","Epoch 73/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.7250 - multi_rwrmse: 1.1540\n","Epoch 74/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.5972 - multi_rwrmse: 1.0488\n","Epoch 75/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.5779 - multi_rwrmse: 1.0454\n","Epoch 76/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.5564 - multi_rwrmse: 1.0077\n","Epoch 77/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.5079 - multi_rwrmse: 1.0153\n","Epoch 78/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.4750 - multi_rwrmse: 0.9565\n","Epoch 79/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4867 - multi_rwrmse: 0.9931\n","Epoch 80/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4719 - multi_rwrmse: 0.9763\n","Epoch 81/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.4039 - multi_rwrmse: 0.8868\n","Epoch 82/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4233 - multi_rwrmse: 0.9326\n","Epoch 83/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.4871 - multi_rwrmse: 0.9780\n","Epoch 84/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4238 - multi_rwrmse: 0.9364\n","Epoch 85/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.3301 - multi_rwrmse: 0.8412\n","Epoch 86/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.3563 - multi_rwrmse: 0.8949\n","Epoch 87/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.3257 - multi_rwrmse: 0.8524\n","Epoch 88/800\n","83/83 [==============================] - 3s 40ms/step - loss: 2.3534 - multi_rwrmse: 0.8694\n","Epoch 89/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.2977 - multi_rwrmse: 0.8339\n","Epoch 90/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.3128 - multi_rwrmse: 0.8653\n","Epoch 91/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.2462 - multi_rwrmse: 0.7928\n","Epoch 92/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.2515 - multi_rwrmse: 0.8190\n","Epoch 93/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.1988 - multi_rwrmse: 0.7798\n","Epoch 94/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.1703 - multi_rwrmse: 0.7397\n","Epoch 95/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.1660 - multi_rwrmse: 0.7539\n","Epoch 96/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.1348 - multi_rwrmse: 0.7265\n","Epoch 97/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.1671 - multi_rwrmse: 0.7580\n","Epoch 98/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.1258 - multi_rwrmse: 0.7152\n","Epoch 99/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.1552 - multi_rwrmse: 0.7618\n","Epoch 100/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.1378 - multi_rwrmse: 0.7359\n","Epoch 101/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.0591 - multi_rwrmse: 0.6892\n","Epoch 102/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.1037 - multi_rwrmse: 0.7298\n","Epoch 103/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.0722 - multi_rwrmse: 0.6866\n","Epoch 104/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.0320 - multi_rwrmse: 0.6852\n","Epoch 105/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.9758 - multi_rwrmse: 0.6337\n","Epoch 106/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9751 - multi_rwrmse: 0.6289\n","Epoch 107/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.9171 - multi_rwrmse: 0.5743\n","Epoch 108/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.9071 - multi_rwrmse: 0.5886\n","Epoch 109/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9222 - multi_rwrmse: 0.6023\n","Epoch 110/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9196 - multi_rwrmse: 0.6019\n","Epoch 111/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.8764 - multi_rwrmse: 0.5646\n","Epoch 112/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.8649 - multi_rwrmse: 0.5577\n","Epoch 113/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.8490 - multi_rwrmse: 0.5484\n","Epoch 114/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.8557 - multi_rwrmse: 0.5594\n","Epoch 115/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8310 - multi_rwrmse: 0.5461\n","Epoch 116/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.8015 - multi_rwrmse: 0.5196\n","Epoch 117/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7778 - multi_rwrmse: 0.5145\n","Epoch 118/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7706 - multi_rwrmse: 0.5142\n","Epoch 119/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.7558 - multi_rwrmse: 0.4954\n","Epoch 120/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7554 - multi_rwrmse: 0.4873\n","Epoch 121/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7055 - multi_rwrmse: 0.4793\n","Epoch 122/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7077 - multi_rwrmse: 0.4610\n","Epoch 123/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6824 - multi_rwrmse: 0.4478\n","Epoch 124/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.7002 - multi_rwrmse: 0.4676\n","Epoch 125/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.6593 - multi_rwrmse: 0.4195\n","Epoch 126/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6628 - multi_rwrmse: 0.4401\n","Epoch 127/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.6246 - multi_rwrmse: 0.4099\n","Epoch 128/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6356 - multi_rwrmse: 0.4104\n","Epoch 129/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.6071 - multi_rwrmse: 0.4083\n","Epoch 130/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.6034 - multi_rwrmse: 0.3952\n","Epoch 131/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.5923 - multi_rwrmse: 0.3985\n","Epoch 132/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5690 - multi_rwrmse: 0.3675\n","Epoch 133/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5788 - multi_rwrmse: 0.3856\n","Epoch 134/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.5298 - multi_rwrmse: 0.3503\n","Epoch 135/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.5254 - multi_rwrmse: 0.3473\n","Epoch 136/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.5201 - multi_rwrmse: 0.3387\n","Epoch 137/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4945 - multi_rwrmse: 0.3228\n","Epoch 138/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4996 - multi_rwrmse: 0.3311\n","Epoch 139/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4699 - multi_rwrmse: 0.3129\n","Epoch 140/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.4685 - multi_rwrmse: 0.3177\n","Epoch 141/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.4483 - multi_rwrmse: 0.2973\n","Epoch 142/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.4488 - multi_rwrmse: 0.3007\n","Epoch 143/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4270 - multi_rwrmse: 0.2822\n","Epoch 144/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4183 - multi_rwrmse: 0.2789\n","Epoch 145/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3953 - multi_rwrmse: 0.2689\n","Epoch 146/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.3855 - multi_rwrmse: 0.2660\n","Epoch 147/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.3757 - multi_rwrmse: 0.2503\n","Epoch 148/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3645 - multi_rwrmse: 0.2446\n","Epoch 149/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.3438 - multi_rwrmse: 0.2347\n","Epoch 150/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.3381 - multi_rwrmse: 0.2263\n","Epoch 151/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.3271 - multi_rwrmse: 0.2217\n","Epoch 152/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.3230 - multi_rwrmse: 0.2173\n","Epoch 153/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3045 - multi_rwrmse: 0.2101\n","Epoch 154/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2950 - multi_rwrmse: 0.2027\n","Epoch 155/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.2822 - multi_rwrmse: 0.1994\n","Epoch 156/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2805 - multi_rwrmse: 0.1968\n","Epoch 157/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.2652 - multi_rwrmse: 0.1873\n","Epoch 158/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.2546 - multi_rwrmse: 0.1794\n","Epoch 159/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.2505 - multi_rwrmse: 0.1842\n","Epoch 160/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.2380 - multi_rwrmse: 0.1670\n","Epoch 161/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.2215 - multi_rwrmse: 0.1605\n","Epoch 162/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.2199 - multi_rwrmse: 0.1568\n","Epoch 163/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.2076 - multi_rwrmse: 0.1539\n","Epoch 164/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.2029 - multi_rwrmse: 0.1459\n","Epoch 165/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1883 - multi_rwrmse: 0.1418\n","Epoch 166/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1802 - multi_rwrmse: 0.1342\n","Epoch 167/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1764 - multi_rwrmse: 0.1333\n","Epoch 168/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1655 - multi_rwrmse: 0.1246\n","Epoch 169/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1583 - multi_rwrmse: 0.1247\n","Epoch 170/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1522 - multi_rwrmse: 0.1168\n","Epoch 171/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1417 - multi_rwrmse: 0.1118\n","Epoch 172/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1363 - multi_rwrmse: 0.1065\n","Epoch 173/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1290 - multi_rwrmse: 0.1054\n","Epoch 174/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1222 - multi_rwrmse: 0.1002\n","Epoch 175/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1129 - multi_rwrmse: 0.0952\n","Epoch 176/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1084 - multi_rwrmse: 0.0927\n","Epoch 177/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.1056 - multi_rwrmse: 0.0944\n","Epoch 178/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1013 - multi_rwrmse: 0.0878\n","Epoch 179/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0921 - multi_rwrmse: 0.0835\n","Epoch 180/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0865 - multi_rwrmse: 0.0779\n","Epoch 181/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0822 - multi_rwrmse: 0.0777\n","Epoch 182/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.0763 - multi_rwrmse: 0.0723\n","Epoch 183/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.0715 - multi_rwrmse: 0.0719\n","Epoch 184/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0667 - multi_rwrmse: 0.0681\n","Epoch 185/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0634 - multi_rwrmse: 0.0673\n","Epoch 186/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.0589 - multi_rwrmse: 0.0628\n","Epoch 187/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.0558 - multi_rwrmse: 0.0617\n","Epoch 188/800\n","83/83 [==============================] - 3s 41ms/step - loss: 1.0524 - multi_rwrmse: 0.0593\n","Epoch 189/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.0497 - multi_rwrmse: 0.0587\n","Epoch 190/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.0461 - multi_rwrmse: 0.0558\n","Epoch 191/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0442 - multi_rwrmse: 0.0551\n","Epoch 192/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.0416 - multi_rwrmse: 0.0535\n","Epoch 193/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.0398 - multi_rwrmse: 0.0525\n","Epoch 194/800\n","83/83 [==============================] - 3s 40ms/step - loss: 1.0369 - multi_rwrmse: 0.0505\n","Epoch 195/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0357 - multi_rwrmse: 0.0499\n","Epoch 196/800\n","83/83 [==============================] - 3s 40ms/step - loss: 1.0341 - multi_rwrmse: 0.0488\n","Epoch 197/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0335 - multi_rwrmse: 0.0488\n","Epoch 198/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.0314 - multi_rwrmse: 0.0472\n","Epoch 199/800\n","83/83 [==============================] - 3s 42ms/step - loss: 1.0321 - multi_rwrmse: 0.0478\n","Epoch 200/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0309 - multi_rwrmse: 0.0469\n","Epoch 201/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.3718 - multi_rwrmse: 0.7808\n","Epoch 202/800\n","83/83 [==============================] - 3s 37ms/step - loss: 4.9046 - multi_rwrmse: 2.7158\n","Epoch 203/800\n","83/83 [==============================] - 3s 37ms/step - loss: 5.4243 - multi_rwrmse: 3.1706\n","Epoch 204/800\n","83/83 [==============================] - 3s 39ms/step - loss: 4.8986 - multi_rwrmse: 2.7679\n","Epoch 205/800\n","83/83 [==============================] - 3s 38ms/step - loss: 4.2445 - multi_rwrmse: 2.2569\n","Epoch 206/800\n","83/83 [==============================] - 3s 37ms/step - loss: 4.0122 - multi_rwrmse: 2.0822\n","Epoch 207/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.5544 - multi_rwrmse: 1.7069\n","Epoch 208/800\n","83/83 [==============================] - 3s 38ms/step - loss: 3.3596 - multi_rwrmse: 1.5374\n","Epoch 209/800\n","83/83 [==============================] - 3s 39ms/step - loss: 3.2057 - multi_rwrmse: 1.5422\n","Epoch 210/800\n","83/83 [==============================] - 3s 40ms/step - loss: 3.1077 - multi_rwrmse: 1.3411\n","Epoch 211/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.1796 - multi_rwrmse: 1.4059\n","Epoch 212/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.0704 - multi_rwrmse: 1.3537\n","Epoch 213/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.0550 - multi_rwrmse: 1.3205\n","Epoch 214/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.8345 - multi_rwrmse: 1.1460\n","Epoch 215/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.7057 - multi_rwrmse: 1.0344\n","Epoch 216/800\n","83/83 [==============================] - 3s 40ms/step - loss: 2.6696 - multi_rwrmse: 0.9867\n","Epoch 217/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.6312 - multi_rwrmse: 1.0326\n","Epoch 218/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.5498 - multi_rwrmse: 0.9340\n","Epoch 219/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.5664 - multi_rwrmse: 0.9366\n","Epoch 220/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.5236 - multi_rwrmse: 0.8729\n","Epoch 221/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.5273 - multi_rwrmse: 0.8571\n","Epoch 222/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.5124 - multi_rwrmse: 0.8938\n","Epoch 223/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4641 - multi_rwrmse: 0.8383\n","Epoch 224/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.5012 - multi_rwrmse: 0.8501\n","Epoch 225/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.5094 - multi_rwrmse: 0.9073\n","Epoch 226/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.4917 - multi_rwrmse: 0.8678\n","Epoch 227/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.4892 - multi_rwrmse: 0.8778\n","Epoch 228/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.4479 - multi_rwrmse: 0.8454\n","Epoch 229/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.3809 - multi_rwrmse: 0.7769\n","Epoch 230/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4095 - multi_rwrmse: 0.7942\n","Epoch 231/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.4064 - multi_rwrmse: 0.8219\n","Epoch 232/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.3799 - multi_rwrmse: 0.7481\n","Epoch 233/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.4247 - multi_rwrmse: 0.8266\n","Epoch 234/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4111 - multi_rwrmse: 0.8112\n","Epoch 235/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.5123 - multi_rwrmse: 0.8509\n","Epoch 236/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.5162 - multi_rwrmse: 0.8901\n","Epoch 237/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.4370 - multi_rwrmse: 0.8351\n","Epoch 238/800\n","83/83 [==============================] - 3s 39ms/step - loss: 2.3982 - multi_rwrmse: 0.7913\n","Epoch 239/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4082 - multi_rwrmse: 0.8092\n","Epoch 240/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.3706 - multi_rwrmse: 0.7874\n","Epoch 241/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.2865 - multi_rwrmse: 0.7365\n","Epoch 242/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.2805 - multi_rwrmse: 0.7052\n","Epoch 243/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.2729 - multi_rwrmse: 0.6991\n","Epoch 244/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.3100 - multi_rwrmse: 0.7203\n","Epoch 245/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.3023 - multi_rwrmse: 0.7298\n","Epoch 246/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.2686 - multi_rwrmse: 0.7044\n","Epoch 247/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.3049 - multi_rwrmse: 0.7334\n","Epoch 248/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.2908 - multi_rwrmse: 0.7143\n","Epoch 249/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.2999 - multi_rwrmse: 0.7045\n","Epoch 250/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.3155 - multi_rwrmse: 0.7251\n","Epoch 251/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.5536 - multi_rwrmse: 0.9869\n","Epoch 252/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.3444 - multi_rwrmse: 0.7548\n","Epoch 253/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.5010 - multi_rwrmse: 0.9217\n","Epoch 254/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4700 - multi_rwrmse: 0.8572\n","Epoch 255/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4140 - multi_rwrmse: 0.8975\n","Epoch 256/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.4257 - multi_rwrmse: 0.8524\n","Epoch 257/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.4887 - multi_rwrmse: 0.9586\n","Epoch 258/800\n","83/83 [==============================] - 3s 34ms/step - loss: 2.4050 - multi_rwrmse: 0.8331\n","Epoch 259/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4139 - multi_rwrmse: 0.8518\n","Epoch 260/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.3949 - multi_rwrmse: 0.8370\n","Epoch 261/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.2975 - multi_rwrmse: 0.7633\n","Epoch 262/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.1840 - multi_rwrmse: 0.6716\n","Epoch 263/800\n","83/83 [==============================] - 3s 34ms/step - loss: 2.1603 - multi_rwrmse: 0.6477\n","Epoch 264/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.1278 - multi_rwrmse: 0.6495\n","Epoch 265/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0982 - multi_rwrmse: 0.6242\n","Epoch 266/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.0950 - multi_rwrmse: 0.6063\n","Epoch 267/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.0524 - multi_rwrmse: 0.5837\n","Epoch 268/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0659 - multi_rwrmse: 0.5974\n","Epoch 269/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.0436 - multi_rwrmse: 0.5860\n","Epoch 270/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0236 - multi_rwrmse: 0.5496\n","Epoch 271/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0043 - multi_rwrmse: 0.5638\n","Epoch 272/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.9780 - multi_rwrmse: 0.5314\n","Epoch 273/800\n","83/83 [==============================] - 3s 35ms/step - loss: 2.0433 - multi_rwrmse: 0.5806\n","Epoch 274/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.9910 - multi_rwrmse: 0.5563\n","Epoch 275/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.9586 - multi_rwrmse: 0.5269\n","Epoch 276/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.9635 - multi_rwrmse: 0.5161\n","Epoch 277/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.9208 - multi_rwrmse: 0.5210\n","Epoch 278/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.8846 - multi_rwrmse: 0.4777\n","Epoch 279/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.9202 - multi_rwrmse: 0.5116\n","Epoch 280/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.8840 - multi_rwrmse: 0.4913\n","Epoch 281/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8955 - multi_rwrmse: 0.4961\n","Epoch 282/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.8579 - multi_rwrmse: 0.4537\n","Epoch 283/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.8299 - multi_rwrmse: 0.4374\n","Epoch 284/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.8495 - multi_rwrmse: 0.4597\n","Epoch 285/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.8631 - multi_rwrmse: 0.4830\n","Epoch 286/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.8124 - multi_rwrmse: 0.4418\n","Epoch 287/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7904 - multi_rwrmse: 0.4121\n","Epoch 288/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7965 - multi_rwrmse: 0.4367\n","Epoch 289/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7723 - multi_rwrmse: 0.4082\n","Epoch 290/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7899 - multi_rwrmse: 0.4352\n","Epoch 291/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7786 - multi_rwrmse: 0.4069\n","Epoch 292/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7662 - multi_rwrmse: 0.4137\n","Epoch 293/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.7449 - multi_rwrmse: 0.3965\n","Epoch 294/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.7376 - multi_rwrmse: 0.4025\n","Epoch 295/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7294 - multi_rwrmse: 0.3958\n","Epoch 296/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7229 - multi_rwrmse: 0.3914\n","Epoch 297/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7391 - multi_rwrmse: 0.4075\n","Epoch 298/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.7000 - multi_rwrmse: 0.3771\n","Epoch 299/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7872 - multi_rwrmse: 0.4283\n","Epoch 300/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.7857 - multi_rwrmse: 0.4715\n","Epoch 301/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8101 - multi_rwrmse: 0.4690\n","Epoch 302/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7943 - multi_rwrmse: 0.4659\n","Epoch 303/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7242 - multi_rwrmse: 0.4208\n","Epoch 304/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.6854 - multi_rwrmse: 0.3912\n","Epoch 305/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.6611 - multi_rwrmse: 0.3856\n","Epoch 306/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.6307 - multi_rwrmse: 0.3464\n","Epoch 307/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6131 - multi_rwrmse: 0.3402\n","Epoch 308/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.5925 - multi_rwrmse: 0.3333\n","Epoch 309/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5695 - multi_rwrmse: 0.3086\n","Epoch 310/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.5449 - multi_rwrmse: 0.2906\n","Epoch 311/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.5650 - multi_rwrmse: 0.3095\n","Epoch 312/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5522 - multi_rwrmse: 0.3060\n","Epoch 313/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5405 - multi_rwrmse: 0.2899\n","Epoch 314/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5224 - multi_rwrmse: 0.2874\n","Epoch 315/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.5280 - multi_rwrmse: 0.2887\n","Epoch 316/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.5065 - multi_rwrmse: 0.2718\n","Epoch 317/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5166 - multi_rwrmse: 0.2872\n","Epoch 318/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4949 - multi_rwrmse: 0.2709\n","Epoch 319/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4879 - multi_rwrmse: 0.2650\n","Epoch 320/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4789 - multi_rwrmse: 0.2613\n","Epoch 321/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.4678 - multi_rwrmse: 0.2497\n","Epoch 322/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4579 - multi_rwrmse: 0.2464\n","Epoch 323/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4465 - multi_rwrmse: 0.2479\n","Epoch 324/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.4382 - multi_rwrmse: 0.2318\n","Epoch 325/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4397 - multi_rwrmse: 0.2506\n","Epoch 326/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4095 - multi_rwrmse: 0.2167\n","Epoch 327/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.4150 - multi_rwrmse: 0.2273\n","Epoch 328/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.4186 - multi_rwrmse: 0.2348\n","Epoch 329/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3909 - multi_rwrmse: 0.2076\n","Epoch 330/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3823 - multi_rwrmse: 0.2071\n","Epoch 331/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3844 - multi_rwrmse: 0.2064\n","Epoch 332/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3686 - multi_rwrmse: 0.2028\n","Epoch 333/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3519 - multi_rwrmse: 0.1910\n","Epoch 334/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3535 - multi_rwrmse: 0.1932\n","Epoch 335/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3395 - multi_rwrmse: 0.1889\n","Epoch 336/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3240 - multi_rwrmse: 0.1699\n","Epoch 337/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3215 - multi_rwrmse: 0.1759\n","Epoch 338/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.3103 - multi_rwrmse: 0.1657\n","Epoch 339/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.3138 - multi_rwrmse: 0.1743\n","Epoch 340/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3014 - multi_rwrmse: 0.1634\n","Epoch 341/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2907 - multi_rwrmse: 0.1592\n","Epoch 342/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2792 - multi_rwrmse: 0.1467\n","Epoch 343/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2764 - multi_rwrmse: 0.1514\n","Epoch 344/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.2650 - multi_rwrmse: 0.1408\n","Epoch 345/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2569 - multi_rwrmse: 0.1393\n","Epoch 346/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2467 - multi_rwrmse: 0.1350\n","Epoch 347/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2501 - multi_rwrmse: 0.1348\n","Epoch 348/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2385 - multi_rwrmse: 0.1349\n","Epoch 349/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2285 - multi_rwrmse: 0.1229\n","Epoch 350/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.2201 - multi_rwrmse: 0.1232\n","Epoch 351/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2098 - multi_rwrmse: 0.1147\n","Epoch 352/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.2012 - multi_rwrmse: 0.1075\n","Epoch 353/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1966 - multi_rwrmse: 0.1052\n","Epoch 354/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1941 - multi_rwrmse: 0.1073\n","Epoch 355/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1829 - multi_rwrmse: 0.0966\n","Epoch 356/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1804 - multi_rwrmse: 0.1019\n","Epoch 357/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1680 - multi_rwrmse: 0.0915\n","Epoch 358/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1615 - multi_rwrmse: 0.0859\n","Epoch 359/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1541 - multi_rwrmse: 0.0824\n","Epoch 360/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1468 - multi_rwrmse: 0.0785\n","Epoch 361/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1415 - multi_rwrmse: 0.0754\n","Epoch 362/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1362 - multi_rwrmse: 0.0731\n","Epoch 363/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1316 - multi_rwrmse: 0.0715\n","Epoch 364/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1243 - multi_rwrmse: 0.0671\n","Epoch 365/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1191 - multi_rwrmse: 0.0639\n","Epoch 366/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1140 - multi_rwrmse: 0.0617\n","Epoch 367/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1080 - multi_rwrmse: 0.0595\n","Epoch 368/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.1036 - multi_rwrmse: 0.0567\n","Epoch 369/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0996 - multi_rwrmse: 0.0547\n","Epoch 370/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0940 - multi_rwrmse: 0.0518\n","Epoch 371/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0910 - multi_rwrmse: 0.0503\n","Epoch 372/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0842 - multi_rwrmse: 0.0453\n","Epoch 373/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0791 - multi_rwrmse: 0.0424\n","Epoch 374/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0749 - multi_rwrmse: 0.0400\n","Epoch 375/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0710 - multi_rwrmse: 0.0388\n","Epoch 376/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0674 - multi_rwrmse: 0.0369\n","Epoch 377/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0634 - multi_rwrmse: 0.0350\n","Epoch 378/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0598 - multi_rwrmse: 0.0319\n","Epoch 379/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0550 - multi_rwrmse: 0.0305\n","Epoch 380/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0519 - multi_rwrmse: 0.0279\n","Epoch 381/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0477 - multi_rwrmse: 0.0262\n","Epoch 382/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0454 - multi_rwrmse: 0.0246\n","Epoch 383/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0419 - multi_rwrmse: 0.0231\n","Epoch 384/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0383 - multi_rwrmse: 0.0206\n","Epoch 385/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0369 - multi_rwrmse: 0.0198\n","Epoch 386/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0334 - multi_rwrmse: 0.0178\n","Epoch 387/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0314 - multi_rwrmse: 0.0172\n","Epoch 388/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0302 - multi_rwrmse: 0.0165\n","Epoch 389/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0271 - multi_rwrmse: 0.0148\n","Epoch 390/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0247 - multi_rwrmse: 0.0134\n","Epoch 391/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0240 - multi_rwrmse: 0.0136\n","Epoch 392/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0221 - multi_rwrmse: 0.0118\n","Epoch 393/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0204 - multi_rwrmse: 0.0113\n","Epoch 394/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0193 - multi_rwrmse: 0.0103\n","Epoch 395/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0182 - multi_rwrmse: 0.0102\n","Epoch 396/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0173 - multi_rwrmse: 0.0093\n","Epoch 397/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0168 - multi_rwrmse: 0.0093\n","Epoch 398/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0159 - multi_rwrmse: 0.0084\n","Epoch 399/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0155 - multi_rwrmse: 0.0083\n","Epoch 400/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0152 - multi_rwrmse: 0.0083\n","Epoch 401/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7311 - multi_rwrmse: 0.3719\n","Epoch 402/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.5947 - multi_rwrmse: 0.9002\n","Epoch 403/800\n","83/83 [==============================] - 3s 37ms/step - loss: 3.5429 - multi_rwrmse: 1.6238\n","Epoch 404/800\n","83/83 [==============================] - 3s 36ms/step - loss: 4.1714 - multi_rwrmse: 2.1673\n","Epoch 405/800\n","83/83 [==============================] - 3s 37ms/step - loss: 4.1067 - multi_rwrmse: 2.1960\n","Epoch 406/800\n","83/83 [==============================] - 3s 37ms/step - loss: 3.6770 - multi_rwrmse: 1.8250\n","Epoch 407/800\n","83/83 [==============================] - 3s 39ms/step - loss: 3.1758 - multi_rwrmse: 1.4967\n","Epoch 408/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.8357 - multi_rwrmse: 1.1831\n","Epoch 409/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.6261 - multi_rwrmse: 1.0426\n","Epoch 410/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.5243 - multi_rwrmse: 0.9416\n","Epoch 411/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.4692 - multi_rwrmse: 0.9036\n","Epoch 412/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.3776 - multi_rwrmse: 0.8368\n","Epoch 413/800\n","83/83 [==============================] - 3s 39ms/step - loss: 2.3371 - multi_rwrmse: 0.7846\n","Epoch 414/800\n","83/83 [==============================] - 3s 41ms/step - loss: 2.3334 - multi_rwrmse: 0.8237\n","Epoch 415/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.2020 - multi_rwrmse: 0.6861\n","Epoch 416/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.1731 - multi_rwrmse: 0.6818\n","Epoch 417/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.1219 - multi_rwrmse: 0.6294\n","Epoch 418/800\n","83/83 [==============================] - 3s 39ms/step - loss: 2.0547 - multi_rwrmse: 0.5592\n","Epoch 419/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.0888 - multi_rwrmse: 0.5991\n","Epoch 420/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0906 - multi_rwrmse: 0.5889\n","Epoch 421/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.0753 - multi_rwrmse: 0.5958\n","Epoch 422/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0570 - multi_rwrmse: 0.5748\n","Epoch 423/800\n","83/83 [==============================] - 3s 39ms/step - loss: 2.0522 - multi_rwrmse: 0.5575\n","Epoch 424/800\n","83/83 [==============================] - 3s 39ms/step - loss: 2.0238 - multi_rwrmse: 0.5437\n","Epoch 425/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0358 - multi_rwrmse: 0.5524\n","Epoch 426/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.0073 - multi_rwrmse: 0.5504\n","Epoch 427/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0317 - multi_rwrmse: 0.5455\n","Epoch 428/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0450 - multi_rwrmse: 0.5910\n","Epoch 429/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.0364 - multi_rwrmse: 0.5643\n","Epoch 430/800\n","83/83 [==============================] - 3s 39ms/step - loss: 2.0375 - multi_rwrmse: 0.5580\n","Epoch 431/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0211 - multi_rwrmse: 0.5454\n","Epoch 432/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.0131 - multi_rwrmse: 0.5467\n","Epoch 433/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.0341 - multi_rwrmse: 0.5494\n","Epoch 434/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.0156 - multi_rwrmse: 0.5599\n","Epoch 435/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.9924 - multi_rwrmse: 0.5381\n","Epoch 436/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.9983 - multi_rwrmse: 0.5363\n","Epoch 437/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9660 - multi_rwrmse: 0.5126\n","Epoch 438/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9673 - multi_rwrmse: 0.5148\n","Epoch 439/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9758 - multi_rwrmse: 0.5300\n","Epoch 440/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.9838 - multi_rwrmse: 0.5325\n","Epoch 441/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.9664 - multi_rwrmse: 0.5156\n","Epoch 442/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.9581 - multi_rwrmse: 0.5085\n","Epoch 443/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9365 - multi_rwrmse: 0.5009\n","Epoch 444/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9634 - multi_rwrmse: 0.5104\n","Epoch 445/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9342 - multi_rwrmse: 0.4977\n","Epoch 446/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.9500 - multi_rwrmse: 0.5025\n","Epoch 447/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.9337 - multi_rwrmse: 0.5145\n","Epoch 448/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.9603 - multi_rwrmse: 0.5133\n","Epoch 449/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9434 - multi_rwrmse: 0.5184\n","Epoch 450/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.9266 - multi_rwrmse: 0.5050\n","Epoch 451/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.9676 - multi_rwrmse: 0.5328\n","Epoch 452/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.9806 - multi_rwrmse: 0.5513\n","Epoch 453/800\n","83/83 [==============================] - 3s 39ms/step - loss: 2.0459 - multi_rwrmse: 0.6103\n","Epoch 454/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.2896 - multi_rwrmse: 0.8087\n","Epoch 455/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.3167 - multi_rwrmse: 0.8695\n","Epoch 456/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.4468 - multi_rwrmse: 1.0022\n","Epoch 457/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.2862 - multi_rwrmse: 0.7423\n","Epoch 458/800\n","83/83 [==============================] - 3s 39ms/step - loss: 2.1851 - multi_rwrmse: 0.7301\n","Epoch 459/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.1413 - multi_rwrmse: 0.6906\n","Epoch 460/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9501 - multi_rwrmse: 0.5333\n","Epoch 461/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.9112 - multi_rwrmse: 0.5152\n","Epoch 462/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8432 - multi_rwrmse: 0.4546\n","Epoch 463/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.8253 - multi_rwrmse: 0.4402\n","Epoch 464/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.8183 - multi_rwrmse: 0.4478\n","Epoch 465/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.8027 - multi_rwrmse: 0.4295\n","Epoch 466/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7918 - multi_rwrmse: 0.4287\n","Epoch 467/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.7616 - multi_rwrmse: 0.3981\n","Epoch 468/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7764 - multi_rwrmse: 0.4298\n","Epoch 469/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.7395 - multi_rwrmse: 0.3871\n","Epoch 470/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.7495 - multi_rwrmse: 0.3961\n","Epoch 471/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7381 - multi_rwrmse: 0.3988\n","Epoch 472/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.7565 - multi_rwrmse: 0.4087\n","Epoch 473/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.7436 - multi_rwrmse: 0.4019\n","Epoch 474/800\n","83/83 [==============================] - 3s 40ms/step - loss: 1.7245 - multi_rwrmse: 0.3859\n","Epoch 475/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.7256 - multi_rwrmse: 0.3827\n","Epoch 476/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.7043 - multi_rwrmse: 0.3841\n","Epoch 477/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7101 - multi_rwrmse: 0.3795\n","Epoch 478/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7028 - multi_rwrmse: 0.3798\n","Epoch 479/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.6790 - multi_rwrmse: 0.3590\n","Epoch 480/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.6985 - multi_rwrmse: 0.3771\n","Epoch 481/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.6630 - multi_rwrmse: 0.3488\n","Epoch 482/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.6625 - multi_rwrmse: 0.3499\n","Epoch 483/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.6704 - multi_rwrmse: 0.3625\n","Epoch 484/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.6664 - multi_rwrmse: 0.3543\n","Epoch 485/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.6525 - multi_rwrmse: 0.3487\n","Epoch 486/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.6406 - multi_rwrmse: 0.3393\n","Epoch 487/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.6334 - multi_rwrmse: 0.3385\n","Epoch 488/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.6045 - multi_rwrmse: 0.3127\n","Epoch 489/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.6087 - multi_rwrmse: 0.3284\n","Epoch 490/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.6048 - multi_rwrmse: 0.3197\n","Epoch 491/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.6305 - multi_rwrmse: 0.3409\n","Epoch 492/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5930 - multi_rwrmse: 0.3153\n","Epoch 493/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.6102 - multi_rwrmse: 0.3203\n","Epoch 494/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5872 - multi_rwrmse: 0.3195\n","Epoch 495/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5966 - multi_rwrmse: 0.3191\n","Epoch 496/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5664 - multi_rwrmse: 0.3000\n","Epoch 497/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.5697 - multi_rwrmse: 0.3055\n","Epoch 498/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.5578 - multi_rwrmse: 0.2955\n","Epoch 499/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5527 - multi_rwrmse: 0.2910\n","Epoch 500/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5277 - multi_rwrmse: 0.2835\n","Epoch 501/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5185 - multi_rwrmse: 0.2734\n","Epoch 502/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5177 - multi_rwrmse: 0.2825\n","Epoch 503/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5090 - multi_rwrmse: 0.2708\n","Epoch 504/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.5221 - multi_rwrmse: 0.2884\n","Epoch 505/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4901 - multi_rwrmse: 0.2624\n","Epoch 506/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5051 - multi_rwrmse: 0.2732\n","Epoch 507/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4682 - multi_rwrmse: 0.2455\n","Epoch 508/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4870 - multi_rwrmse: 0.2645\n","Epoch 509/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.4728 - multi_rwrmse: 0.2537\n","Epoch 510/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4669 - multi_rwrmse: 0.2537\n","Epoch 511/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4492 - multi_rwrmse: 0.2416\n","Epoch 512/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4542 - multi_rwrmse: 0.2401\n","Epoch 513/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4445 - multi_rwrmse: 0.2347\n","Epoch 514/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.4299 - multi_rwrmse: 0.2236\n","Epoch 515/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.4216 - multi_rwrmse: 0.2316\n","Epoch 516/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4108 - multi_rwrmse: 0.2151\n","Epoch 517/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.4086 - multi_rwrmse: 0.2240\n","Epoch 518/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.4014 - multi_rwrmse: 0.2159\n","Epoch 519/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3957 - multi_rwrmse: 0.2060\n","Epoch 520/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3734 - multi_rwrmse: 0.1969\n","Epoch 521/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.3701 - multi_rwrmse: 0.1965\n","Epoch 522/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3668 - multi_rwrmse: 0.1938\n","Epoch 523/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.3502 - multi_rwrmse: 0.1851\n","Epoch 524/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3463 - multi_rwrmse: 0.1858\n","Epoch 525/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3400 - multi_rwrmse: 0.1797\n","Epoch 526/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.3375 - multi_rwrmse: 0.1808\n","Epoch 527/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3234 - multi_rwrmse: 0.1688\n","Epoch 528/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3167 - multi_rwrmse: 0.1699\n","Epoch 529/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3113 - multi_rwrmse: 0.1636\n","Epoch 530/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3156 - multi_rwrmse: 0.1723\n","Epoch 531/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.3023 - multi_rwrmse: 0.1606\n","Epoch 532/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.2937 - multi_rwrmse: 0.1567\n","Epoch 533/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2831 - multi_rwrmse: 0.1516\n","Epoch 534/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2750 - multi_rwrmse: 0.1465\n","Epoch 535/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2701 - multi_rwrmse: 0.1428\n","Epoch 536/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2666 - multi_rwrmse: 0.1416\n","Epoch 537/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.2548 - multi_rwrmse: 0.1356\n","Epoch 538/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.2472 - multi_rwrmse: 0.1312\n","Epoch 539/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2467 - multi_rwrmse: 0.1332\n","Epoch 540/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2374 - multi_rwrmse: 0.1261\n","Epoch 541/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2284 - multi_rwrmse: 0.1224\n","Epoch 542/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2231 - multi_rwrmse: 0.1217\n","Epoch 543/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.2184 - multi_rwrmse: 0.1166\n","Epoch 544/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.2089 - multi_rwrmse: 0.1117\n","Epoch 545/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1993 - multi_rwrmse: 0.1044\n","Epoch 546/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1970 - multi_rwrmse: 0.1063\n","Epoch 547/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1924 - multi_rwrmse: 0.1005\n","Epoch 548/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1910 - multi_rwrmse: 0.1029\n","Epoch 549/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1809 - multi_rwrmse: 0.0964\n","Epoch 550/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1781 - multi_rwrmse: 0.0974\n","Epoch 551/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1686 - multi_rwrmse: 0.0903\n","Epoch 552/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1639 - multi_rwrmse: 0.0901\n","Epoch 553/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1521 - multi_rwrmse: 0.0807\n","Epoch 554/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1532 - multi_rwrmse: 0.0813\n","Epoch 555/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1432 - multi_rwrmse: 0.0751\n","Epoch 556/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1416 - multi_rwrmse: 0.0760\n","Epoch 557/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1344 - multi_rwrmse: 0.0705\n","Epoch 558/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1288 - multi_rwrmse: 0.0681\n","Epoch 559/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1239 - multi_rwrmse: 0.0652\n","Epoch 560/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1216 - multi_rwrmse: 0.0656\n","Epoch 561/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1158 - multi_rwrmse: 0.0613\n","Epoch 562/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1124 - multi_rwrmse: 0.0626\n","Epoch 563/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1037 - multi_rwrmse: 0.0554\n","Epoch 564/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0995 - multi_rwrmse: 0.0536\n","Epoch 565/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0926 - multi_rwrmse: 0.0489\n","Epoch 566/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0917 - multi_rwrmse: 0.0500\n","Epoch 567/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0865 - multi_rwrmse: 0.0463\n","Epoch 568/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0837 - multi_rwrmse: 0.0451\n","Epoch 569/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0795 - multi_rwrmse: 0.0428\n","Epoch 570/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0757 - multi_rwrmse: 0.0402\n","Epoch 571/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0715 - multi_rwrmse: 0.0383\n","Epoch 572/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0689 - multi_rwrmse: 0.0373\n","Epoch 573/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0628 - multi_rwrmse: 0.0334\n","Epoch 574/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0625 - multi_rwrmse: 0.0331\n","Epoch 575/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.0570 - multi_rwrmse: 0.0306\n","Epoch 576/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0535 - multi_rwrmse: 0.0283\n","Epoch 577/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.0501 - multi_rwrmse: 0.0272\n","Epoch 578/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0475 - multi_rwrmse: 0.0257\n","Epoch 579/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0451 - multi_rwrmse: 0.0239\n","Epoch 580/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0427 - multi_rwrmse: 0.0234\n","Epoch 581/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0386 - multi_rwrmse: 0.0203\n","Epoch 582/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0376 - multi_rwrmse: 0.0204\n","Epoch 583/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0339 - multi_rwrmse: 0.0181\n","Epoch 584/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0319 - multi_rwrmse: 0.0171\n","Epoch 585/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0300 - multi_rwrmse: 0.0163\n","Epoch 586/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0272 - multi_rwrmse: 0.0143\n","Epoch 587/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0262 - multi_rwrmse: 0.0140\n","Epoch 588/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0244 - multi_rwrmse: 0.0129\n","Epoch 589/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0232 - multi_rwrmse: 0.0124\n","Epoch 590/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0212 - multi_rwrmse: 0.0113\n","Epoch 591/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0202 - multi_rwrmse: 0.0110\n","Epoch 592/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0182 - multi_rwrmse: 0.0099\n","Epoch 593/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0176 - multi_rwrmse: 0.0095\n","Epoch 594/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0167 - multi_rwrmse: 0.0089\n","Epoch 595/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0157 - multi_rwrmse: 0.0085\n","Epoch 596/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0148 - multi_rwrmse: 0.0079\n","Epoch 597/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0145 - multi_rwrmse: 0.0079\n","Epoch 598/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0139 - multi_rwrmse: 0.0075\n","Epoch 599/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0137 - multi_rwrmse: 0.0075\n","Epoch 600/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0136 - multi_rwrmse: 0.0074\n","Epoch 601/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.5863 - multi_rwrmse: 0.2924\n","Epoch 602/800\n","83/83 [==============================] - 3s 37ms/step - loss: 2.1922 - multi_rwrmse: 0.6608\n","Epoch 603/800\n","83/83 [==============================] - 3s 37ms/step - loss: 3.0057 - multi_rwrmse: 1.3437\n","Epoch 604/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.4830 - multi_rwrmse: 1.6480\n","Epoch 605/800\n","83/83 [==============================] - 3s 36ms/step - loss: 3.0312 - multi_rwrmse: 1.3176\n","Epoch 606/800\n","83/83 [==============================] - 3s 39ms/step - loss: 2.7099 - multi_rwrmse: 1.1106\n","Epoch 607/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.5343 - multi_rwrmse: 0.9442\n","Epoch 608/800\n","83/83 [==============================] - 3s 38ms/step - loss: 2.2748 - multi_rwrmse: 0.7758\n","Epoch 609/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.1305 - multi_rwrmse: 0.6447\n","Epoch 610/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.0414 - multi_rwrmse: 0.5920\n","Epoch 611/800\n","83/83 [==============================] - 3s 36ms/step - loss: 2.0048 - multi_rwrmse: 0.5640\n","Epoch 612/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.9350 - multi_rwrmse: 0.5248\n","Epoch 613/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.9055 - multi_rwrmse: 0.4932\n","Epoch 614/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8987 - multi_rwrmse: 0.4876\n","Epoch 615/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.8669 - multi_rwrmse: 0.4628\n","Epoch 616/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.8708 - multi_rwrmse: 0.4680\n","Epoch 617/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8630 - multi_rwrmse: 0.4628\n","Epoch 618/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.8680 - multi_rwrmse: 0.4646\n","Epoch 619/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.8416 - multi_rwrmse: 0.4426\n","Epoch 620/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8476 - multi_rwrmse: 0.4546\n","Epoch 621/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8411 - multi_rwrmse: 0.4529\n","Epoch 622/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8348 - multi_rwrmse: 0.4441\n","Epoch 623/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.8379 - multi_rwrmse: 0.4366\n","Epoch 624/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.8350 - multi_rwrmse: 0.4399\n","Epoch 625/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.8395 - multi_rwrmse: 0.4393\n","Epoch 626/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8437 - multi_rwrmse: 0.4617\n","Epoch 627/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8167 - multi_rwrmse: 0.4293\n","Epoch 628/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8226 - multi_rwrmse: 0.4265\n","Epoch 629/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.8391 - multi_rwrmse: 0.4518\n","Epoch 630/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.8220 - multi_rwrmse: 0.4335\n","Epoch 631/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.8229 - multi_rwrmse: 0.4407\n","Epoch 632/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8177 - multi_rwrmse: 0.4410\n","Epoch 633/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8492 - multi_rwrmse: 0.4615\n","Epoch 634/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.8220 - multi_rwrmse: 0.4492\n","Epoch 635/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7949 - multi_rwrmse: 0.4186\n","Epoch 636/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.8210 - multi_rwrmse: 0.4310\n","Epoch 637/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.8215 - multi_rwrmse: 0.4412\n","Epoch 638/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.8058 - multi_rwrmse: 0.4165\n","Epoch 639/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7901 - multi_rwrmse: 0.4176\n","Epoch 640/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7855 - multi_rwrmse: 0.4176\n","Epoch 641/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7778 - multi_rwrmse: 0.4075\n","Epoch 642/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.7770 - multi_rwrmse: 0.4060\n","Epoch 643/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7826 - multi_rwrmse: 0.4128\n","Epoch 644/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7897 - multi_rwrmse: 0.4292\n","Epoch 645/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7717 - multi_rwrmse: 0.4186\n","Epoch 646/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.8018 - multi_rwrmse: 0.4328\n","Epoch 647/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7629 - multi_rwrmse: 0.4026\n","Epoch 648/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7643 - multi_rwrmse: 0.4033\n","Epoch 649/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7476 - multi_rwrmse: 0.4007\n","Epoch 650/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7696 - multi_rwrmse: 0.4018\n","Epoch 651/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7616 - multi_rwrmse: 0.4097\n","Epoch 652/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7641 - multi_rwrmse: 0.3942\n","Epoch 653/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7496 - multi_rwrmse: 0.4009\n","Epoch 654/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7386 - multi_rwrmse: 0.3888\n","Epoch 655/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7367 - multi_rwrmse: 0.3838\n","Epoch 656/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7410 - multi_rwrmse: 0.3922\n","Epoch 657/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.7195 - multi_rwrmse: 0.3851\n","Epoch 658/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.7144 - multi_rwrmse: 0.3765\n","Epoch 659/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.7170 - multi_rwrmse: 0.3787\n","Epoch 660/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.6922 - multi_rwrmse: 0.3671\n","Epoch 661/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6912 - multi_rwrmse: 0.3659\n","Epoch 662/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.6917 - multi_rwrmse: 0.3713\n","Epoch 663/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6971 - multi_rwrmse: 0.3721\n","Epoch 664/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.6844 - multi_rwrmse: 0.3557\n","Epoch 665/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.7823 - multi_rwrmse: 0.4296\n","Epoch 666/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.6872 - multi_rwrmse: 0.3686\n","Epoch 667/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6864 - multi_rwrmse: 0.3756\n","Epoch 668/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6943 - multi_rwrmse: 0.3708\n","Epoch 669/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6667 - multi_rwrmse: 0.3535\n","Epoch 670/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.6551 - multi_rwrmse: 0.3527\n","Epoch 671/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.6459 - multi_rwrmse: 0.3440\n","Epoch 672/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.6389 - multi_rwrmse: 0.3429\n","Epoch 673/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6245 - multi_rwrmse: 0.3299\n","Epoch 674/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.6147 - multi_rwrmse: 0.3256\n","Epoch 675/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.6042 - multi_rwrmse: 0.3172\n","Epoch 676/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.5931 - multi_rwrmse: 0.3151\n","Epoch 677/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.6136 - multi_rwrmse: 0.3162\n","Epoch 678/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.6057 - multi_rwrmse: 0.3211\n","Epoch 679/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.5866 - multi_rwrmse: 0.3129\n","Epoch 680/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5863 - multi_rwrmse: 0.3121\n","Epoch 681/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5715 - multi_rwrmse: 0.3032\n","Epoch 682/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.5638 - multi_rwrmse: 0.2941\n","Epoch 683/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5614 - multi_rwrmse: 0.2924\n","Epoch 684/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5600 - multi_rwrmse: 0.2952\n","Epoch 685/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5629 - multi_rwrmse: 0.2965\n","Epoch 686/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.5348 - multi_rwrmse: 0.2808\n","Epoch 687/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.5420 - multi_rwrmse: 0.2882\n","Epoch 688/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5252 - multi_rwrmse: 0.2807\n","Epoch 689/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5096 - multi_rwrmse: 0.2623\n","Epoch 690/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.5208 - multi_rwrmse: 0.2788\n","Epoch 691/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.4975 - multi_rwrmse: 0.2606\n","Epoch 692/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.5049 - multi_rwrmse: 0.2646\n","Epoch 693/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.4837 - multi_rwrmse: 0.2489\n","Epoch 694/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.5035 - multi_rwrmse: 0.2713\n","Epoch 695/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4820 - multi_rwrmse: 0.2578\n","Epoch 696/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4723 - multi_rwrmse: 0.2487\n","Epoch 697/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.4611 - multi_rwrmse: 0.2446\n","Epoch 698/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4515 - multi_rwrmse: 0.2354\n","Epoch 699/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.4549 - multi_rwrmse: 0.2379\n","Epoch 700/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.4490 - multi_rwrmse: 0.2367\n","Epoch 701/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.4412 - multi_rwrmse: 0.2328\n","Epoch 702/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.4410 - multi_rwrmse: 0.2337\n","Epoch 703/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4320 - multi_rwrmse: 0.2243\n","Epoch 704/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4262 - multi_rwrmse: 0.2197\n","Epoch 705/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4102 - multi_rwrmse: 0.2124\n","Epoch 706/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.4028 - multi_rwrmse: 0.2094\n","Epoch 707/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.4055 - multi_rwrmse: 0.2150\n","Epoch 708/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.3990 - multi_rwrmse: 0.2086\n","Epoch 709/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3923 - multi_rwrmse: 0.2066\n","Epoch 710/800\n","83/83 [==============================] - 3s 42ms/step - loss: 1.3808 - multi_rwrmse: 0.2030\n","Epoch 711/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.3762 - multi_rwrmse: 0.1999\n","Epoch 712/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3742 - multi_rwrmse: 0.2039\n","Epoch 713/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3592 - multi_rwrmse: 0.1889\n","Epoch 714/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3558 - multi_rwrmse: 0.1900\n","Epoch 715/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.3497 - multi_rwrmse: 0.1802\n","Epoch 716/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.3423 - multi_rwrmse: 0.1821\n","Epoch 717/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.3371 - multi_rwrmse: 0.1758\n","Epoch 718/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.3395 - multi_rwrmse: 0.1825\n","Epoch 719/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3216 - multi_rwrmse: 0.1694\n","Epoch 720/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.3158 - multi_rwrmse: 0.1695\n","Epoch 721/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.3082 - multi_rwrmse: 0.1622\n","Epoch 722/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.3100 - multi_rwrmse: 0.1623\n","Epoch 723/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2984 - multi_rwrmse: 0.1564\n","Epoch 724/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.2947 - multi_rwrmse: 0.1540\n","Epoch 725/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2819 - multi_rwrmse: 0.1454\n","Epoch 726/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2834 - multi_rwrmse: 0.1518\n","Epoch 727/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2721 - multi_rwrmse: 0.1419\n","Epoch 728/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2721 - multi_rwrmse: 0.1453\n","Epoch 729/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2608 - multi_rwrmse: 0.1385\n","Epoch 730/800\n","83/83 [==============================] - 3s 39ms/step - loss: 1.2585 - multi_rwrmse: 0.1353\n","Epoch 731/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.2509 - multi_rwrmse: 0.1361\n","Epoch 732/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2428 - multi_rwrmse: 0.1263\n","Epoch 733/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2365 - multi_rwrmse: 0.1278\n","Epoch 734/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.2225 - multi_rwrmse: 0.1139\n","Epoch 735/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2182 - multi_rwrmse: 0.1157\n","Epoch 736/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2170 - multi_rwrmse: 0.1130\n","Epoch 737/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2138 - multi_rwrmse: 0.1135\n","Epoch 738/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.2061 - multi_rwrmse: 0.1070\n","Epoch 739/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.2013 - multi_rwrmse: 0.1075\n","Epoch 740/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1946 - multi_rwrmse: 0.1012\n","Epoch 741/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1905 - multi_rwrmse: 0.1024\n","Epoch 742/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1852 - multi_rwrmse: 0.0981\n","Epoch 743/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1792 - multi_rwrmse: 0.0956\n","Epoch 744/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1722 - multi_rwrmse: 0.0891\n","Epoch 745/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1671 - multi_rwrmse: 0.0866\n","Epoch 746/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1621 - multi_rwrmse: 0.0859\n","Epoch 747/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1563 - multi_rwrmse: 0.0832\n","Epoch 748/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1584 - multi_rwrmse: 0.0832\n","Epoch 749/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1470 - multi_rwrmse: 0.0768\n","Epoch 750/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1416 - multi_rwrmse: 0.0739\n","Epoch 751/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.1369 - multi_rwrmse: 0.0710\n","Epoch 752/800\n","83/83 [==============================] - 3s 38ms/step - loss: 1.1312 - multi_rwrmse: 0.0686\n","Epoch 753/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1248 - multi_rwrmse: 0.0656\n","Epoch 754/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1238 - multi_rwrmse: 0.0648\n","Epoch 755/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1214 - multi_rwrmse: 0.0633\n","Epoch 756/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1185 - multi_rwrmse: 0.0617\n","Epoch 757/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1123 - multi_rwrmse: 0.0603\n","Epoch 758/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.1072 - multi_rwrmse: 0.0568\n","Epoch 759/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.1038 - multi_rwrmse: 0.0552\n","Epoch 760/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0996 - multi_rwrmse: 0.0529\n","Epoch 761/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0951 - multi_rwrmse: 0.0514\n","Epoch 762/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0927 - multi_rwrmse: 0.0484\n","Epoch 763/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0856 - multi_rwrmse: 0.0442\n","Epoch 764/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0835 - multi_rwrmse: 0.0443\n","Epoch 765/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0823 - multi_rwrmse: 0.0451\n","Epoch 766/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0790 - multi_rwrmse: 0.0428\n","Epoch 767/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0735 - multi_rwrmse: 0.0389\n","Epoch 768/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0708 - multi_rwrmse: 0.0380\n","Epoch 769/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0648 - multi_rwrmse: 0.0342\n","Epoch 770/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0641 - multi_rwrmse: 0.0344\n","Epoch 771/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0592 - multi_rwrmse: 0.0317\n","Epoch 772/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0573 - multi_rwrmse: 0.0304\n","Epoch 773/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0545 - multi_rwrmse: 0.0297\n","Epoch 774/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0507 - multi_rwrmse: 0.0268\n","Epoch 775/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0475 - multi_rwrmse: 0.0254\n","Epoch 776/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0458 - multi_rwrmse: 0.0239\n","Epoch 777/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0422 - multi_rwrmse: 0.0227\n","Epoch 778/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0400 - multi_rwrmse: 0.0210\n","Epoch 779/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0371 - multi_rwrmse: 0.0201\n","Epoch 780/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0360 - multi_rwrmse: 0.0189\n","Epoch 781/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0332 - multi_rwrmse: 0.0180\n","Epoch 782/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0313 - multi_rwrmse: 0.0168\n","Epoch 783/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0293 - multi_rwrmse: 0.0158\n","Epoch 784/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.0273 - multi_rwrmse: 0.0144\n","Epoch 785/800\n","83/83 [==============================] - 5s 66ms/step - loss: 1.0260 - multi_rwrmse: 0.0139\n","Epoch 786/800\n","83/83 [==============================] - 5s 64ms/step - loss: 1.0247 - multi_rwrmse: 0.0130\n","Epoch 787/800\n","83/83 [==============================] - 4s 47ms/step - loss: 1.0224 - multi_rwrmse: 0.0117\n","Epoch 788/800\n","83/83 [==============================] - 3s 42ms/step - loss: 1.0211 - multi_rwrmse: 0.0111\n","Epoch 789/800\n","83/83 [==============================] - 5s 61ms/step - loss: 1.0197 - multi_rwrmse: 0.0104\n","Epoch 790/800\n","83/83 [==============================] - 5s 63ms/step - loss: 1.0186 - multi_rwrmse: 0.0098\n","Epoch 791/800\n","83/83 [==============================] - 4s 47ms/step - loss: 1.0172 - multi_rwrmse: 0.0090\n","Epoch 792/800\n","83/83 [==============================] - 4s 42ms/step - loss: 1.0166 - multi_rwrmse: 0.0087\n","Epoch 793/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0152 - multi_rwrmse: 0.0079\n","Epoch 794/800\n","83/83 [==============================] - 3s 37ms/step - loss: 1.0148 - multi_rwrmse: 0.0080\n","Epoch 795/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0140 - multi_rwrmse: 0.0074\n","Epoch 796/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0139 - multi_rwrmse: 0.0074\n","Epoch 797/800\n","83/83 [==============================] - 3s 34ms/step - loss: 1.0128 - multi_rwrmse: 0.0068\n","Epoch 798/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0126 - multi_rwrmse: 0.0067\n","Epoch 799/800\n","83/83 [==============================] - 3s 35ms/step - loss: 1.0123 - multi_rwrmse: 0.0065\n","Epoch 800/800\n","83/83 [==============================] - 3s 36ms/step - loss: 1.0122 - multi_rwrmse: 0.0064\n","\n","Epoch 00801: final model weights set to stochastic weight average\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7c9e9ff964a0>"]},"metadata":{},"execution_count":46}],"source":["# Comiple model\n","# Contrastive loss - contrastive_loss all 3 heads evaluated on MAE\n","model.compile(loss=contrastive_loss_3h, optimizer=opt_adamW, metrics=[multi_rwrmse])\n","\n","# Train model\n","model.fit(x=x_train, y=y_embed, epochs=800, batch_size=16, callbacks=[swa], shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1701153036498,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"},"user_tz":-480},"id":"jCGA2twxV4D5","outputId":"ee38b048-7ef0-4643-bc3a-5e0a78538615"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":47}],"source":["incl_control"]},{"cell_type":"code","source":["VT.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_GeSY33Aneww","executionInfo":{"status":"ok","timestamp":1701153038672,"user_tz":-480,"elapsed":3,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"}},"outputId":"98ea6436-e657-4f31-f746-e99e67a5ae3c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(101, 18211)"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"__tLD0ywjQMu"},"outputs":[],"source":["# Load in submission set\n","df_id = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Input/singlecell/id_map_submission.csv')\n","\n","# Convert to Morgan fingerprints\n","df_X = np.zeros([df_id.shape[0], 2048])\n","for i in range(df_id.shape[0]):\n","\tdf_X[i, :] = np.array(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(df_id[\"SMILES\"][i]), radius=2, nBits=2048))\n","\n","# One hot encode the cell types\n","n_cell_types = 6\n","cells = [\"B cells\",  \"Myeloid cells\", \"NK cells\", \"T cells CD4+\", \"T cells CD8+\", \"T regulatory cells\"]\n","one_hot = pd.DataFrame(np.zeros([df_id.shape[0], n_cell_types]), columns=cells)\n","\n","# Fill in one_hot\n","one_hot_test = pd.get_dummies(df_id[\"cell_type\"]) * 1.0\n","one_hot[\"B cells\"] = one_hot_test[\"B cells\"]\n","one_hot[\"Myeloid cells\"] = one_hot_test[\"Myeloid cells\"]\n","one_hot = np.array(one_hot)\n","\n","# Control and dose for test\n","# Control (1 - control, 0 - non-control)\n","test_control = np.zeros([df_id.shape[0], 1])\n","# Dose (1 uM for all compounds)\n","test_dose = np.ones((df_id.shape[0], 1))\n","\n","# Log10 transform n_atoms, molecular weight, and molar refractivity\n","df_id[\"n_atoms\"] = df_id[\"n_atoms\"].map(np.log10)\n","df_id[\"mol_weight\"] = df_id[\"mol_weight\"].map(np.log10)\n","df_id[\"MR\"] = df_id[\"MR\"].map(np.log10)\n","\n","# Merge to construct test matrix\n","if incl_control:\n","\t# Test matrix if controls and dose used\n","\tone_hot = np.concatenate((one_hot, scaler.transform(df_id[[\"log_P\", \"MR\"]])), axis=1)\n","\tone_hot = np.concatenate((one_hot, test_control), axis=1)\n","\tx_test = np.concatenate((one_hot, df_X), axis=1)\n","else:\n","\t# Test matrix if controls / dose not used\n","\tone_hot = np.concatenate((one_hot, scaler.transform(df_id[[\"log_P\", \"MR\"]])), axis=1)\n","\tx_test = np.concatenate((one_hot, df_X), axis=1)\n","\n","del one_hot, one_hot_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2YRO7yv2m3Q"},"outputs":[],"source":["# Augment features with average drug response and average cell type response to drugs for test\n","\n","if drug_response:\n","  df_id_alt = df_id.iloc[:, 0:5]\n","  df_id_alt = df_id_alt.merge(mean_smiles_name, on='SMILES', how='left')\n","  mean_smiles_test = np.array(df_id_alt.iloc[:, 5:])\n","  # Concat with x_test\n","  x_test = np.concatenate((x_test, scaler_drug.transform(mean_smiles_test)), axis=1)\n","\n","if cell_type_response:\n","  df_id_alt = df_id.iloc[:, 0:5]\n","  df_id_alt = df_id_alt.merge(mean_cell_type, on='cell_type', how='left')\n","  mean_cell_test = np.array(df_id_alt.iloc[:, 5:])\n","  # Concat with x_Test\n","  x_test = np.concatenate((x_test, scaler_cell.transform(mean_cell_test)), axis=1)\n","\n","if drug_lfc_response:\n","  df_id_alt = df_id.iloc[:, 0:5]\n","  df_id_alt = df_id_alt.merge(mean_smiles_lfc_name, on='SMILES', how='left')\n","  mean_smiles_lfc_test = np.array(df_id_alt.iloc[:, 5:])\n","  # Concat with x_test\n","  x_test = np.concatenate((x_test, scaler_drug_lfc.transform(mean_smiles_lfc_test)), axis=1)\n","\n","if cell_type_lfc_response:\n","  df_id_alt = df_id.iloc[:, 0:5]\n","  df_id_alt = df_id_alt.merge(mean_cell_lfc_type, on='cell_type', how='left')\n","  mean_cell_lfc_test = np.array(df_id_alt.iloc[:, 5:])\n","  # Concat with x_test\n","  x_test = np.concatenate((x_test, scaler_cell_lfc.transform(mean_cell_lfc_test)), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":453,"status":"ok","timestamp":1701153046242,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"},"user_tz":-480},"id":"wkFZwkIdv1Ug","outputId":"0d2b171a-2c63-4a9d-94c7-837fbf83dcad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(255, 2056)"]},"metadata":{},"execution_count":51}],"source":["x_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2346,"status":"ok","timestamp":1701153049960,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"},"user_tz":-480},"id":"KsR4HVjZK2Zl","outputId":"1dd5fe3d-2fce-4022-be94-3d6211833666"},"outputs":[{"output_type":"stream","name":"stdout","text":["18/18 [==============================] - 0s 3ms/step\n","0 0.5125406851086056\n","1 0.5112158307464528\n","2 0.5119393549501484\n"]}],"source":["# Predict on x_train copy and split into chunks\n","nh = 3\n","output_emb = np.split(model.predict(x_train_copy), nh, axis=1)\n","\n","# Choose output type based on VT project\n","if VT_project:\n","  # Ensemble weights\n","  weights = []\n","  for i in range(nh):\n","    weights.append(K.eval(rwrmse(y_train_copy, output_emb[i])))\n","\n","  # Construct ensembling weights\n","  weights = np.array(weights)\n","  weights = 1. - weights\n","  weights = weights / np.sum(weights)\n","\n","  # Print losses\n","  y_output_loss = []\n","  for i in range(nh):\n","    y_output_loss.append(K.eval(rwrmse(y_train_copy, output_emb[i])))\n","    print(i, y_output_loss[i])\n","else:\n","  # Ensemble weights\n","  weights = []\n","  for i in range(nh):\n","    weights.append(K.eval(rwrmse(y_train_copy, (output_emb[i] @ VT))))\n","\n","  # Construct ensembling weights\n","  weights = np.array(weights)\n","  weights = 1. - weights\n","  weights = weights / np.sum(weights)\n","\n","  # Embedding high\n","  y_output_loss = []\n","  for i in range(nh):\n","    y_output_loss.append(K.eval(rwrmse(y_train_copy, (output_emb[i] @ VT))))\n","    print(i, y_output_loss[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wflpgg_jSNfU"},"outputs":[],"source":["# Select the best head and also loss weight ensemble the 3 heads\n","# Head index\n","head_idx = y_output_loss.index(min(y_output_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1701153051154,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"},"user_tz":-480},"id":"H5wae9jLR5h9","outputId":"3a8c42d7-bf4f-4d9f-8eff-a3ee09ed2971"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":54}],"source":["head_idx"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17112,"status":"ok","timestamp":1701153069321,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"},"user_tz":-480},"id":"g9zYXQ6vjTZV","outputId":"c0a1ac29-a1a6-4560-94f5-2efbbaf4f3ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["8/8 [==============================] - 0s 4ms/step\n","082f032913803e988aff81d\n"]}],"source":["# Predict on test and split into chunks\n","# Best head prediction (head_idx)\n","output_emb = np.split(model.predict(x_test), nh, axis=1)\n","\n","if VT_project:\n","  output_high = output_emb[head_idx]\n","else:\n","  if run_svd:\n","    output_high = output_emb[head_idx] @ VT\n","  if run_autoencoder:\n","    output_high = decoder.predict(output_emb[head_idx])\n","\n","# Read in submission file\n","submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Input/singlecell/sample_submission.csv')\n","submission.iloc[:, 1:] = output_high\n","\n","# Save as submission\n","# Generate truncated SHA256 hash\n","truncated_hash = hashlib.sha256(os.urandom(23)).hexdigest()[:23]\n","\n","submission_path = '/content/drive/MyDrive/Colab Notebooks/Output/ecfp_reg_8lselu_multi_v485_' + truncated_hash + '.csv'\n","submission.to_csv(submission_path, index=False)\n","\n","# Print hash\n","print(truncated_hash)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1701153069321,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"},"user_tz":-480},"id":"iZYt6AuzC-Ns","outputId":"a569903b-6e96-44c6-a8b7-e7dea207ea72"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(75.41930454532292, -27.907574788717152)"]},"metadata":{},"execution_count":56}],"source":["np.max(output_high), np.min(output_high)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGG1EWgDqy9C"},"outputs":[],"source":["# Use equal weights\n","weights_equal = False\n","\n","if weights_equal:\n","  weights = [1/nh] * nh"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1701153069321,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"},"user_tz":-480},"id":"6FXuXifI516R","outputId":"133049e4-65cb-4953-ff69-559060d3f489"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.33289486, 0.33379963, 0.33330552])"]},"metadata":{},"execution_count":58}],"source":["weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15656,"status":"ok","timestamp":1701153084976,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"},"user_tz":-480},"id":"pYfHuYvPC7A3","outputId":"34c97ac6-46bf-4494-f9cb-f2f712736ef0"},"outputs":[{"output_type":"stream","name":"stdout","text":["191ef44d952ae115a60171e\n"]}],"source":["# Get ensemble (multi-head embedding blend)\n","# Ensemble of embedding outputs and inverse transform with VT\n","output_high = np.zeros([255, n_genes])\n","\n","for i in range(nh):\n","  if VT_project:\n","    # If using SVD VT project matrix\n","    output_high += (weights[i] * output_emb[i])\n","  else:\n","    output_high += (weights[i] * (output_emb[i] @ VT))\n","\n","# Read in submission file\n","submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Input/singlecell/sample_submission.csv')\n","submission.iloc[:, 1:] = output_high\n","\n","# Generate truncated SHA256 hash\n","truncated_hash = hashlib.sha256(os.urandom(23)).hexdigest()[:23]\n","\n","submission_path = '/content/drive/MyDrive/Colab Notebooks/Output/ecfp_reg_8lselu_multi_ensemble_low_v486_' + truncated_hash + '.csv'\n","submission.to_csv(submission_path, index=False)\n","\n","# Print hash\n","print(truncated_hash)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1701153084976,"user":{"displayName":"Henry Wang","userId":"05370281669692758120"},"user_tz":-480},"id":"jt0ZfitDi6xE","outputId":"ec6761a2-30e4-4813-a982-e1996b5fa34c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(74.01194911064934, -28.12256482084174)"]},"metadata":{},"execution_count":60}],"source":["np.max(output_high), np.min(output_high)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztquaTtsgvln"},"outputs":[],"source":["# Save model\n","# Use .keras extension to save whole model\n","filepath = '/content/drive/MyDrive/Colab Notebooks/Models/ecfp_reg_8lselu_stack_v486_' + truncated_hash + '.keras'\n","model.save(filepath)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1MLLJmD8la-iNLslRoWs5umPYHdlukIpp","timestamp":1697803881212}],"gpuType":"V100","mount_file_id":"1SnEaRZum-1qwz4VEa-Txd_QNO-m6uV-r","authorship_tag":"ABX9TyO4B4jZfhnLPxsAxRZ7nfdi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}